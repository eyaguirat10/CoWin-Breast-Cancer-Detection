{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Sisp9ycxEeYi",
        "uMR43XtqGXNe",
        "SJol103lGu-L",
        "-RzRGl2L-RHY",
        "QVtuMW1o-y02",
        "wsMmPEmcVBV9",
        "3HbaSKJ_V_QJ",
        "QyCGhz9fW7ya",
        "ZgsOAHXLXEc7",
        "rkpnFAh2afNM",
        "h6Dk_TSdNp95",
        "PCL2-Ivk-lkt",
        "oAQQgG35-5O9",
        "6yuhwRBVWFGo",
        "gbcczozQWRA4",
        "e0_815nSWYJa",
        "AXW7ILu1XXS6"
      ],
      "authorship_tag": "ABX9TyP+B9LFSZwclKuLcZleHjNd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaguirat10/CoWin-Breast-Cancer-Detection/blob/eya/Eya_Guirat_Breast_Cancer_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Business Understanding"
      ],
      "metadata": {
        "id": "7tAm0gQK_Qv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem Statement**\n",
        "\n",
        "Breast cancer is one of the most common and life-threatening diseases affecting women worldwide. According to the World Health Organization, it accounts for a significant proportion of cancer-related deaths among women, with **approximately 2.3 million new cases diagnosed each year**. While the highest incidence is usually observed in women aged **40 to 70**, younger women are increasingly being diagnosed, highlighting the need for vigilance across all age groups. Men can also develop breast cancer, though it is much rarer.\n",
        "\n",
        "Early detection of breast cancer is crucial because survival rates are significantly higher when the disease is identified at an initial stage. However, **late diagnosis remains common**, particularly in regions with limited access to screening programs, diagnostic facilities, or trained specialists. Factors contributing to delayed detection include:\n",
        "- Socio-economic barriers  \n",
        "- Lack of awareness about breast health  \n",
        "- Cultural stigmas  \n",
        "- Shortages of radiologists or screening centers  \n",
        "\n",
        "In some areas, women may delay seeking care due to fear, misinformation, or limited healthcare infrastructure — leading to advanced diagnoses when treatment is more difficult and costly.\n",
        "\n",
        "Breast cancer can manifest in different forms — **ductal carcinoma, lobular carcinoma, and other subtypes** — each with distinct characteristics and progression rates. The disease may present **asymptomatically** in its early stages, which is why imaging techniques such as **mammography** are critical for screening. Even with mammograms, subtle signs like **microcalcifications** or small lesions can be easily overlooked, even by experienced radiologists.\n",
        "\n",
        "This issue is particularly pressing in regions where incidence is high and **medical resources are limited**, such as parts of **North Africa**, the **Middle East**, and **some areas of the United States**, where datasets like **CBIS-DDSM** and **MIAS** have been collected. These datasets demonstrate the variability in breast tissue density and lesion appearance, increasing the challenge of accurate detection.\n",
        "\n",
        "## Stakeholders Affected\n",
        "\n",
        "- **Doctors / Radiologists**: Responsible for interpreting mammograms and providing medical decisions. Face diagnostic complexity, heavy workloads, and pressure to avoid errors.\n",
        "- **Hospitals and Clinics**: Handle screening, treatment, and patient management. Diagnostic support tools can improve outcomes and reduce costs.\n",
        "- **Public Health Organizations**: Lead screening campaigns and healthcare policy. Better tools improve allocation of resources and reduce mortality.\n",
        "- **Researchers**: Use datasets and AI models to develop new diagnostic tools and improve early detection performance.\n",
        "\n",
        "\n",
        "Given these challenges, there is a **critical need for computer-assisted systems** that help healthcare professionals detect breast cancer early, accurately, and efficiently.\n",
        "\n",
        "Such systems can:\n",
        "- Generate **predictions** and **personalized recommendations** based on mammography or clinical data  \n",
        "- Improve clinical **decision-making** while minimizing risk to patients  \n",
        "- Ensure **role-based access** to data: doctors get detailed results, patients receive **validated, understandable recommendations**  \n",
        "\n",
        "Examples of AI-guided outputs:\n",
        "- Follow-up imaging requests\n",
        "- Lifestyle or risk-reduction recommendations\n",
        "- Alerts for uncertain or borderline diagnosis cases\n",
        "\n",
        "In summary, breast cancer is a complex issue involving **medical, social, and economic factors**. Our project integrates **artificial intelligence** into the diagnostic workflow to:\n",
        "- **Enhance early detection**\n",
        "- **Reduce late diagnoses**\n",
        "- **Provide safe, actionable guidance for patients**\n",
        "\n",
        "Ultimately, the project aims to assist all stakeholders and improve breast cancer management outcomes.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **Business Objective (BO)**\n",
        "\n",
        "1.  ### Determine whether a tumor is malignant or benign based on morphological data extracted from breast tissue imagery, in order to assist clinicians in initial diagnosis.\n",
        "\n",
        "\n",
        "2.  ### Characterize and differentiate malignant tumor profiles into distinct groups based on their severity or aggressiveness, enabling more targeted follow-up strategies.\n",
        "   \n",
        "3.  ### Propose individualized recommendations for new patients by comparing their physiological and biochemical profiles to previously identified cancer risk patterns.  \n",
        "\n",
        "---\n",
        "\n",
        "## **Data Science Objectives (DSO)**\n",
        "\n",
        "1.  ### Develop a classification system that distinguishes between benign and malignant tumors using morphological features from the WDBC dataset and evaluate its accuracy using appropriate performance metrics.\n",
        "\n",
        "\n",
        "2.  ### Identify natural groupings within malignant tumor cases using unsupervised clustering techniques in order to define clinically relevant cancer subtypes.\n",
        "   \n",
        "3.  ### Implement a recommendation system that maps new patient profiles (from the Coimbra dataset) to known cluster patterns and delivers personalized insights based on proximity to known cancer risk profiles."
      ],
      "metadata": {
        "id": "ErnHy9MpHH8k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DSO1: Predict the diagnosis type — **M (Malignant)** or **B (Benign)**\n",
        "\n",
        "| Modèles             | Liste des variables | Liste des paramètres |\n",
        "|---------------------|---------------------|-----------------------|\n",
        "| GRU SVM             |                     |                       |\n",
        "| SVM                 |                     |                       |\n",
        "| Linear Regression   |                     |                       |\n",
        "| MLP                 |                     |                       |\n",
        "| Nearest Neighbor    |                     |                       |\n",
        "| Softmax Regression  |                     |                       |\n",
        "| XGBOOST (new)       |                     |                       |\n",
        "| Random Forest (new) |                     |                       |\n"
      ],
      "metadata": {
        "id": "D7qSIlYrr40m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DSO2: Cluster diagnosis patterns\n",
        "\n",
        "| Modèles                | Liste des variables | Liste des paramètres |\n",
        "|------------------------|---------------------|-----------------------|\n",
        "| Kmeans                 |                     |                       |\n",
        "| DBSCAN                 |                     |                       |\n",
        "| Gaussian Mixture Model |                     |                       |\n"
      ],
      "metadata": {
        "id": "7XtgAj7PsL6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DSO3: Cluster-based recommendation system\n",
        "\n",
        "| Modèles               | Liste des variables | Liste des paramètres |\n",
        "|------------------------|---------------------|-----------------------|\n",
        "| KNeighborsClassifier   |                     |                       |\n",
        "| DecisionTreeClassifier |                     |                       |\n",
        "| Apriori                |                     |                       |\n"
      ],
      "metadata": {
        "id": "80HBcJglsQ8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Data Understanding"
      ],
      "metadata": {
        "id": "uCLqt27yAHW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##II.1. DSO1 : Predict the diagnosis type — M (Malignant) or B (Benign)"
      ],
      "metadata": {
        "id": "Sisp9ycxEeYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "F0El3yokAak9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "jb3UcdpYC_aB",
        "outputId": "e3304294-454f-4dd1-c789-c862b79f6f3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Datasets/CancerData1.csv\"\n",
        "df = pd.read_csv(path)\n"
      ],
      "metadata": {
        "id": "lbJkQ3t4DUhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dimensions :\", df.shape)\n",
        "print(\"Colonnes :\", df.columns.tolist())\n",
        "print(\"\\nTypes :\", df.dtypes)"
      ],
      "metadata": {
        "id": "jQg4BLJoDYPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")"
      ],
      "metadata": {
        "id": "wps3ydkgjWDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "GLd3G5ORjgHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values\")\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
        "\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Count': missing_data,\n",
        "    'Missing Percentage': missing_percent\n",
        "})\n",
        "print(missing_df[missing_df['Missing Count'] > 0])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.heatmap(df.isnull(), yticklabels=False, cbar=True, cmap='viridis')\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vOeYViA8j0Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Basic statistics\")\n",
        "print(df.describe())\n",
        "\n",
        "# For the diagnosis column specifically\n",
        "print(\"\\n Diagnosis distribution\")\n",
        "print(df['diagnosis'].value_counts())\n",
        "print(f\"Malignant Percentage: {(df['diagnosis'] == 'M').mean()*100:.2f}%\")"
      ],
      "metadata": {
        "id": "c76-_4XZkCSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df.corr(numeric_only=True), cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Corrélation entre les variables numériques\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2BdKT0sKEA3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Outlier detection\")\n",
        "\n",
        "# Method 1: IQR for numerical columns\n",
        "def detect_outliers_iqr(column):\n",
        "    Q1 = column.quantile(0.25)\n",
        "    Q3 = column.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = column[(column < lower_bound) | (column > upper_bound)]\n",
        "    return outliers\n",
        "\n",
        "# Check outliers in key numerical columns\n",
        "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "print(\"Outliers in key features:\")\n",
        "for col in numerical_cols[:5]:  # Check first 5 numerical columns\n",
        "    outliers = detect_outliers_iqr(df[col])\n",
        "    print(f\"{col}: {len(outliers)} outliers\")\n",
        "\n",
        "# Visualize outliers for key features\n",
        "key_features = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean']\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, feature in enumerate(key_features):\n",
        "    df.boxplot(column=feature, ax=axes[i])\n",
        "    axes[i].set_title(f'Outliers in {feature}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZoEA1qG0kiDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data quality summary\")\n",
        "print(f\"Total records: {len(df)}\")\n",
        "print(f\"Total features: {len(df.columns)}\")\n",
        "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
        "\n",
        "# Check for constant columns (columns with only one value)\n",
        "constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
        "print(f\"Constant columns: {constant_cols}\")\n",
        "\n",
        "# Check for columns with too many zeros\n",
        "print(\"\\n columns with many zeros\")\n",
        "for col in numerical_cols:\n",
        "    zero_percent = (df[col] == 0).mean() * 100\n",
        "    if zero_percent > 50:  # Show columns with more than 50% zeros\n",
        "        print(f\"{col}: {zero_percent:.2f}% zeros\")"
      ],
      "metadata": {
        "id": "H8R1UIHNk_zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Target variable analysis\")\n",
        "diagnosis_counts = df['diagnosis'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Subplot 1: Count plot\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.countplot(data=df, x='diagnosis')\n",
        "plt.title('Diagnosis Distribution')\n",
        "\n",
        "# Subplot 2: Pie chart\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.pie(diagnosis_counts.values, labels=diagnosis_counts.index, autopct='%1.1f%%')\n",
        "plt.title('Diagnosis Proportion')\n",
        "\n",
        "# Subplot 3: Statistics by diagnosis\n",
        "plt.subplot(1, 3, 3)\n",
        "diagnosis_stats = df.groupby('diagnosis')['radius_mean'].agg(['mean', 'std', 'min', 'max'])\n",
        "diagnosis_stats.plot(kind='bar', ax=plt.gca())\n",
        "plt.title('Radius Mean by Diagnosis')\n",
        "plt.xticks(rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Diagnosis value counts:\\n{diagnosis_counts}\")"
      ],
      "metadata": {
        "id": "wZS1g6WFldHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Correlation analysis\")\n",
        "\n",
        "# Convert diagnosis to numerical for correlation\n",
        "df_corr = df.copy()\n",
        "df_corr['diagnosis_numeric'] = df_corr['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Correlation with target\n",
        "corr_with_target = df_corr.corr(numeric_only=True)['diagnosis_numeric'].sort_values(ascending=False)\n",
        "print(\"Top 10 features correlated with diagnosis:\")\n",
        "print(corr_with_target.head(10))\n",
        "\n",
        "print(\"\\n Bottom 10 features correlated with diagnosis:\")\n",
        "print(corr_with_target.tail(10))\n",
        "\n",
        "# Plot correlation heatmap for top features\n",
        "top_corr_features = corr_with_target.index[1:11]  # Exclude diagnosis itself\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df_corr[top_corr_features].corr(), annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap of Top 10 Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ve2dhGLyli9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"diagnosis\", data=df)\n",
        "plt.title(\"Distribution des diagnostics (Bénin/Malin)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dXfiZDoLD5H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare a key feature between malignant and benign\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=df, x='diagnosis', y='radius_mean')\n",
        "plt.title('Tumor Radius: Malignant vs Benign')\n",
        "plt.ylabel('Mean Radius')\n",
        "plt.xlabel('Diagnosis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Gp_6gYkCmJU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting few key features to compare\n",
        "features_to_plot = ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for i, feature in enumerate(features_to_plot):\n",
        "    sns.boxplot(data=df, x='diagnosis', y=feature, ax=axes[i])\n",
        "    axes[i].set_title(f'{feature} by Diagnosis')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kvQQnmrBmYLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find two features most correlated with diagnosis\n",
        "top_two = corr_with_target.index[1:3]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.scatterplot(data=df, x=top_two[0], y=top_two[1], hue='diagnosis', style='diagnosis')\n",
        "plt.title(f'Relationship between {top_two[0]} and {top_two[1]}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FRewb9plmdYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##II.2. Dataset 2: DSO2 + DSO3"
      ],
      "metadata": {
        "id": "50fznEfHTaiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Dataset_ML/dataR2.csv\"\n",
        "df2 = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "7v1zuSHQTcDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "8Uxn31EJVe1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.tail()"
      ],
      "metadata": {
        "id": "EWNZoavvVjZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.dtypes"
      ],
      "metadata": {
        "id": "_4JuurMtVqoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "1zBq98W4VttT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe()"
      ],
      "metadata": {
        "id": "Jd_0E5-dVzH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Missing Values Analysis"
      ],
      "metadata": {
        "id": "TSphnxwtV2bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we calculate how many missing (null) values exist in each column of the dataset. This information is important because columns with many missing values may need special handling, such as imputation or removal, to ensure the quality of our analysis and models."
      ],
      "metadata": {
        "id": "X4MpySwwWeP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "info_df = pd.DataFrame({\n",
        "        'Column': df2.columns,\n",
        "        'Non_Null_Count': df2.count(),\n",
        "        'Null_Count': df2.isnull().sum(),\n",
        "        'Missing_%': (df2.isnull().sum() / len(df2) * 100).round(2)\n",
        "    })\n",
        "print(info_df.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "d8F_mNzfWPy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Duplicate Analysis"
      ],
      "metadata": {
        "id": "RV-vAQkDWbX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we check the dataset for duplicate rows. Duplicate records can skew analysis and models by overrepresenting certain data points."
      ],
      "metadata": {
        "id": "8VhfcqTuWqk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_count = df2.duplicated().sum()\n",
        "print(f\"\\nNumber of duplicate rows: {duplicate_count}\")\n",
        "if duplicate_count > 0:\n",
        "    print(f\"Percentage: {(duplicate_count/len(df2)*100):.2f}%\")\n",
        "print()"
      ],
      "metadata": {
        "id": "ScaGAz3uWvEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Visualization"
      ],
      "metadata": {
        "id": "eqQI7lvqWzYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boxplots are used to visualize the distribution of numerical data and detect outliers. They display the median, quartiles, and potential extreme values for each feature, helping us understand variability and spot anomalies that may need further investigation or treatment."
      ],
      "metadata": {
        "id": "Ob6_QjekW2IF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create boxplots for numerical columns"
      ],
      "metadata": {
        "id": "d2R3-kWqW8h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "numerical_cols = df2.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "numerical_cols = [col for col in numerical_cols if df2[col].dropna().shape[0] > 0]\n",
        "cols_per_fig = 9  # number of boxplots per figure\n",
        "\n",
        "for start in range(0, len(numerical_cols), cols_per_fig):\n",
        "    end = start + cols_per_fig\n",
        "    batch = numerical_cols[start:end]\n",
        "\n",
        "    plt.figure(figsize=(14, 10))\n",
        "    for i, col in enumerate(batch, 1):\n",
        "        plt.subplot(3, 3, i)  # 2 rows, 3 columns\n",
        "        sns.boxplot(y=df2[col])\n",
        "        plt.title(col)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IjcqjFjpW-eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset was constructed for research purposes → outliers are not errors, they are anomalies related to the disease."
      ],
      "metadata": {
        "id": "mTx99LqUXFIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Visualization:"
      ],
      "metadata": {
        "id": "DXRhYDv3XHXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation matrix between variables\n",
        "df_features = df2.drop(columns=['Classification'])\n",
        "plt.figure(figsize=(18, 12))\n",
        "sns.heatmap(df2.corr(), annot=False, cmap='coolwarm')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nBfPVz2kXJaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correlation matrix of variables with the target\n",
        "# creation of numerical diagnosis\n",
        "\n",
        "df2.corr()['Classification'].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "SSI42OzMXN7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Principal Component Analysis (PCA)"
      ],
      "metadata": {
        "id": "E8U1gUQGX1B5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standardisation\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Select only numeric variables\n",
        "X = df2.select_dtypes(include=[np.number])\n",
        "\n",
        "# --- 2. Standardisation\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# --- 3. PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Explained variance\n",
        "print(\"Variance expliquée par PC1 et PC2 :\", pca.explained_variance_ratio_)\n"
      ],
      "metadata": {
        "id": "8UaoIzdnX28V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- correlation circle ---\n",
        "def plot_correlation_circle(pca, features, dim1=1, dim2=2):\n",
        "    pcs = pca.components_\n",
        "    pc1 = pcs[dim1-1]\n",
        "    pc2 = pcs[dim2-1]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "\n",
        "    # Circle\n",
        "    circle = plt.Circle((0,0), 1, color='grey', fill=False, linestyle='--')\n",
        "    ax.add_artist(circle)\n",
        "\n",
        "    # Axes\n",
        "    ax.axhline(0, color='black', lw=1)\n",
        "    ax.axvline(0, color='black', lw=1)\n",
        "\n",
        "    # Variables\n",
        "    for i, feature in enumerate(features):\n",
        "        x = pc1[i]\n",
        "        y = pc2[i]\n",
        "        ax.arrow(0, 0, x, y, head_width=0.03, head_length=0.03, linewidth=1.2)\n",
        "        ax.text(x*1.08, y*1.08, feature, fontsize=11)\n",
        "\n",
        "    ax.set_xlabel(f\"PC{dim1} ({round(pca.explained_variance_ratio_[dim1-1]*100,2)}%)\", fontsize=13)\n",
        "    ax.set_ylabel(f\"PC{dim2} ({round(pca.explained_variance_ratio_[dim2-1]*100,2)}%)\", fontsize=13)\n",
        "    ax.set_title(\"Cercle de corrélation PCA\", fontsize=16)\n",
        "    ax.set_xlim(-1.1, 1.1)\n",
        "    ax.set_ylim(-1.1, 1.1)\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "\n",
        "# --- Function call ---\n",
        "plot_correlation_circle(pca, X.columns)\n"
      ],
      "metadata": {
        "id": "hJX3BscYX42C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#III. Data Preparation"
      ],
      "metadata": {
        "id": "r9c0IHsCAblc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##III.1. DSO1 : Predict the diagnosis type — M (Malignant) or B (Benign)"
      ],
      "metadata": {
        "id": "uMR43XtqGXNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['Unnamed: 32', 'id'], inplace=True, errors='ignore')\n",
        "df.columns"
      ],
      "metadata": {
        "id": "8GhCoAL5Ae7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "sbXCsgKPuJHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X = df.drop('diagnosis', axis=1)\n",
        "y = df[\"diagnosis\"]\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "scores = X_scaled"
      ],
      "metadata": {
        "id": "agUVfBBXrgQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA()\n",
        "pca.fit(X_scaled)"
      ],
      "metadata": {
        "id": "Gi9CERyBuT1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "plt.plot(cumulative_variance)\n",
        "plt.xlabel(\"Number of Components\")\n",
        "plt.ylabel(\"Cumulative Explained Variance\")\n",
        "plt.title(\"PCA Explained Variance\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dlSrArsdujp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigvals = pca.explained_variance_\n",
        "loadings_corr = pca.components_.T * np.sqrt(eigvals)  # shape (n_features, 2)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 7))\n",
        "theta = np.linspace(0, 2*np.pi, 500)\n",
        "ax.plot(np.cos(theta), np.sin(theta), 'b--', alpha=0.6)\n",
        "\n",
        "names = X.columns\n",
        "for i, name in enumerate(names):\n",
        "    x, y_ = loadings_corr[i, 0], loadings_corr[i, 1]\n",
        "    ax.arrow(0, 0, x, y_, color='crimson', alpha=0.75,\n",
        "             head_width=0.02, length_includes_head=True)\n",
        "    ax.text(x*1.07, y_*1.07, name, fontsize=8)\n",
        "\n",
        "ax.axhline(0, color='grey', lw=1, ls='--')\n",
        "ax.axvline(0, color='grey', lw=1, ls='--')\n",
        "ax.set_xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% var)\")\n",
        "ax.set_ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% var)\")\n",
        "ax.set_title(\"PCA Correlation Circle\")\n",
        "ax.set_aspect('equal', 'box')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tEzi-knnunTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pcs = [f\"PC{i}\" for i in range(1, scores.shape[1] + 1)]\n",
        "scores_df = pd.DataFrame(scores @ pca.components_.T, columns=pcs)\n",
        "scores_df[\"diagnosis\"] = df[\"diagnosis\"]"
      ],
      "metadata": {
        "id": "Qcera5N0uq43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7, 6))\n",
        "sns.scatterplot(\n",
        "    data=scores_df, x=\"PC1\", y=\"PC2\",\n",
        "    hue=\"diagnosis\",\n",
        "    palette={\"M\": \"crimson\", \"B\": \"steelblue\"},\n",
        "    alpha=0.75, edgecolor=\"white\", s=45\n",
        ")\n",
        "plt.axhline(0, color=\"grey\", ls=\"--\", lw=1)\n",
        "plt.axvline(0, color=\"grey\", ls=\"--\", lw=1)\n",
        "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% var)\")\n",
        "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% var)\")\n",
        "plt.title(\"Samples in PC space (PC1 vs PC2)\")\n",
        "plt.legend(title=\"Diagnosis\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NVd7nabYuvBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Data preparation for the model"
      ],
      "metadata": {
        "id": "0hGEu2ha9kdL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I start from the cleaned dataframe `df` (after removing `id` and `Unnamed: 32`).\n",
        "- I create:\n",
        "  - `X_model` = copy of all 30 feature columns  \n",
        "  - `y_model` = copy of the `diagnosis` column\n",
        "- I encode the target so that:\n",
        "  - `B` → 0 (Benign)  \n",
        "  - `M` → 1 (Malignant)\n",
        "- The input features used by the model are the **standardised features** `X_scaled` (output of `StandardScaler`), so each variable has mean 0 and variance 1.\n",
        "- I split the data into **70% training / 30% test** using `train_test_split` with `stratify=y_model` to keep the same proportion of benign and malignant cases in both sets.  \n",
        "  This reproduces the protocol used in the research paper."
      ],
      "metadata": {
        "id": "3JOcyP7Y9pwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defensive copies (good practice)\n",
        "X_model = X.copy()\n",
        "y_model = y.copy()"
      ],
      "metadata": {
        "id": "7raD8zOLAkf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode target: Malignant = 1, Benign = 0\n",
        "y_model = y_model.map({'M': 1, 'B': 0})"
      ],
      "metadata": {
        "id": "GawV11nMr70h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 70% train / 30% test, stratified by the target\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_model, test_size=0.3, random_state=42, stratify=y_model\n",
        ")"
      ],
      "metadata": {
        "id": "S-XD1B7Kr9wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we build and evaluate a **Random Forest classifier** to predict whether a tumour is **benign (0)** or **malignant (1)** using the 30 numerical features of the dataset (data.csv)"
      ],
      "metadata": {
        "id": "6wqZXHeA9XyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##III.2. Dataset 2: DSO2 + DSO3"
      ],
      "metadata": {
        "id": "We52Wf77TrlB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DSO2"
      ],
      "metadata": {
        "id": "bXEyKXC-x2at"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = [col for col in df2.columns if col != \"Classification\"]\n",
        "X2 = df2[features].values\n",
        "y2 = df2[\"Classification\"].values\n"
      ],
      "metadata": {
        "id": "Dvyz39tITxV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled2 = scaler.fit_transform(X2)"
      ],
      "metadata": {
        "id": "dK0JPNIfY_Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#IV. Modeling"
      ],
      "metadata": {
        "id": "szQFNS8IAfNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IV.1. DSO1 : Predict the diagnosis type — M (Malignant) or B (Benign)"
      ],
      "metadata": {
        "id": "SJol103lGu-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest Model"
      ],
      "metadata": {
        "id": "E3EidUNlyv1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Training the Random Forest"
      ],
      "metadata": {
        "id": "-RzRGl2L-RHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I create a `RandomForestClassifier` with:\n",
        "  - `n_estimators = 100` trees,\n",
        "  - `class_weight = 'balanced'` to compensate the slight class imbalance,\n",
        "  - `random_state = 42` for reproducibility.\n",
        "- I fit the model **only on the training set** (`X_train`, `y_train`)."
      ],
      "metadata": {
        "id": "i-j-xOpR-U11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "# Fit on training data only\n",
        "rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "bgZHNt1HsPbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Visualisation of one tree"
      ],
      "metadata": {
        "id": "QVtuMW1o-y02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The Random Forest is an ensemble of 100 trees, which is hard to visualise directly.\n",
        "- For interpretability, I plot **one tree** from the forest (`rf.estimators_[5]`) with a maximum depth of 3.\n",
        "- This shows how the model uses the most important features (for example `area_worst`, `concave points_mean`, etc.) to split between benign and malignant tumours."
      ],
      "metadata": {
        "id": "KNqCY2k5-2B9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "features = X.columns\n",
        "estimator = rf.estimators_[5]\n",
        "plt.figure(figsize=(24, 10))\n",
        "plot_tree(\n",
        "    estimator,\n",
        "    feature_names=features,\n",
        "    class_names=[\"Benign\", \"Malignant\"],\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    max_depth=3,\n",
        "    fontsize=10\n",
        ")\n",
        "plt.title(\"Visualisation d'un arbre du Random Forest (profondeur limitée à 3)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ho2-idjntk1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "s4wwy6Q8rdGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part, we build and tune a **Multi-Layer Perceptron (MLP) classifier** to predict whether a tumour is **benign (0)** or **malignant (1)** using the same 30 numerical features as for the Random Forest.\n"
      ],
      "metadata": {
        "id": "oWOPdNhkU-rN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data preparation for the MLP"
      ],
      "metadata": {
        "id": "wsMmPEmcVBV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Start from the cleaned dataframe `df`.\n",
        "- Create:\n",
        "  - `X_model_2` = copy of the 30 feature columns  \n",
        "  - `y_model_2` = copy of the `diagnosis` column\n",
        "- Encode the target:\n",
        "  - `B` → 0 (Benign)\n",
        "  - `M` → 1 (Malignant)\n",
        "- Use the standardised features `X_scaled` as input to the MLP.\n",
        "- Split into **70% train / 30% test**, stratified by the target, to keep the same class proportions."
      ],
      "metadata": {
        "id": "7WoxIf5gVHG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "u908Io3trkL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_model_2 = X.copy()\n",
        "y_model_2 = y.copy()\n",
        "y_model_2 = y_model_2.map({'M': 1, 'B': 0})"
      ],
      "metadata": {
        "id": "ihg34EJfw0Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled,\n",
        "    y_model_2,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y_model_2\n",
        ")"
      ],
      "metadata": {
        "id": "tVu12iudw2iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I use `predict_proba` to get the predicted probability of the malignant class on the test set."
      ],
      "metadata": {
        "id": "jFGMn6qc-_BD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROC curve of the Random Forest on the test set is very close to the top-left\n",
        "corner. The Area Under the Curve is **AUC = 0.997**, which indicates an excellent\n",
        "ability to separate benign (0) from malignant (1) tumours.  \n",
        "The model keeps a very high true positive rate (sensitivity) while maintaining a\n",
        "very low false positive rate, which is desirable in a medical screening context."
      ],
      "metadata": {
        "id": "cUZBGJtGDDIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Base MLP architecture"
      ],
      "metadata": {
        "id": "3HbaSKJ_V_QJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Define a base `MLPClassifier` with:\n",
        "  - activation `relu`\n",
        "  - optimiser `adam`\n",
        "  - batch size 32\n",
        "  - `max_iter = 500`\n",
        "  - `early_stopping = True` with `validation_fraction = 0.2` and `n_iter_no_change = 20`  \n",
        "    → adds an anti-overfitting safety: training stops when validation score stagnates.\n",
        "- The exact hidden layer sizes and regularisation will be chosen by grid search."
      ],
      "metadata": {
        "id": "gCN9-nctWBhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_base = MLPClassifier(\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    batch_size=32,\n",
        "    max_iter=500,\n",
        "    early_stopping=True,      # on garde une sécurité anti-overfitting\n",
        "    validation_fraction=0.2,\n",
        "    n_iter_no_change=20,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "4XMh10dmw5lU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU-SVM"
      ],
      "metadata": {
        "id": "tvzUg6Ty5xty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implement a **GRU-SVM model**: a GRU network that outputs a single linear score,\n",
        "trained with **hinge loss** (SVM style) instead of cross-entropy."
      ],
      "metadata": {
        "id": "uDp-m94TW5It"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Data preparation"
      ],
      "metadata": {
        "id": "QyCGhz9fW7ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The starting point is still `X_scaled` (30 standardised features) and `y`.\n",
        "- For the SVM formulation we encode the labels as:\n",
        "  - `M` → +1\n",
        "  - `B` → −1\n",
        "- GRUs expect a 3D input `(samples, timesteps, features)`.  \n",
        "  Here we treat the 30 features as a “sequence” of length 30 with 1 feature per step:\n",
        "  `X_gru.shape = (n_samples, 30, 1)`.\n",
        "- We perform a **70% / 30%** train–test split, stratified on `y_gru`."
      ],
      "metadata": {
        "id": "4clbss8iW-Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "r4804gDm6ZF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_gru = y.map({'M': 1, 'B': -1}).astype('float32')"
      ],
      "metadata": {
        "id": "-hJUtnSW89uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples, n_features = X_scaled.shape\n",
        "X_gru = X_scaled.reshape(n_samples, n_features, 1)"
      ],
      "metadata": {
        "id": "_P3JXLh29CUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_gru, X_test_gru, y_train_gru, y_test_gru = train_test_split(\n",
        "    X_gru,\n",
        "    y_gru,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y_gru\n",
        ")"
      ],
      "metadata": {
        "id": "uBKJfVq79Q2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####GRU-SVM architecture"
      ],
      "metadata": {
        "id": "ZgsOAHXLXEc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Custom metric `svm_accuracy`:\n",
        "  - takes the **sign** of the model output,\n",
        "  - compares it to the true labels in {−1, +1}.\n",
        "- Model structure:\n",
        "  - one `GRU(32)` layer (sequence → 32-dim embedding),\n",
        "  - one `Dropout(0.3)` layer to reduce overfitting,\n",
        "  - one `Dense(1, activation='linear')` output → raw SVM score.\n",
        "- We compile with:\n",
        "  - optimiser: `Adam(learning_rate=1e-3)`\n",
        "  - loss: `'hinge'` (SVM margin loss)\n",
        "  - metric: `svm_accuracy`."
      ],
      "metadata": {
        "id": "VgD2jbMeXIia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_accuracy(y_true, y_pred):\n",
        "    # signe de la prédiction\n",
        "    y_pred_sign = tf.sign(y_pred)\n",
        "    # si le modèle sort exactement 0, on force à +1\n",
        "    y_pred_sign = tf.where(tf.equal(y_pred_sign, 0.0),\n",
        "                           tf.ones_like(y_pred_sign),\n",
        "                           y_pred_sign)\n",
        "    equal = tf.equal(y_true, y_pred_sign)\n",
        "    return tf.reduce_mean(tf.cast(equal, tf.float32))\n",
        "\n",
        "gru_svm = Sequential([\n",
        "    GRU(32, input_shape=(n_features, 1), return_sequences=False),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='linear')    # sortie linéaire pour hinge\n",
        "])\n",
        "\n",
        "gru_svm.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='hinge',\n",
        "    metrics=[svm_accuracy]\n",
        ")\n"
      ],
      "metadata": {
        "id": "uS8Xh3HT9ut3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Training the GRU-SVM"
      ],
      "metadata": {
        "id": "JvhzFmROXSCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use `EarlyStopping` on `val_loss` with:\n",
        "  - `patience = 30`\n",
        "  - `restore_best_weights = True`\n",
        "- Training configuration:\n",
        "  - validation split: 20% of the training set,\n",
        "  - `epochs = 300` (training may stop earlier thanks to early stopping),\n",
        "  - `batch_size = 32`,\n",
        "  - `verbose = 0` for a clean notebook.\n",
        "- At the end, we print the epoch where training actually stopped."
      ],
      "metadata": {
        "id": "c-shjBiLXT1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history_gru = gru_svm.fit(\n",
        "    X_train_gru, y_train_gru,\n",
        "    validation_split=0.2,\n",
        "    epochs=300,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "print(f\"Training stopped at epoch {len(history_gru.history['loss'])}\")"
      ],
      "metadata": {
        "id": "noe7--o49znf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IV.1. DSO2: Cluster diagnosis patterns"
      ],
      "metadata": {
        "id": "qdr2a8YOT5I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1) Keep only the sick\n",
        "df_cancer = df2[df2[\"Classification\"] == 2].copy() #df containing only patients\n",
        "df_non_cancer = df2[df2[\"Classification\"] == 1].copy() #df containing only non-patients\n",
        "print(df_cancer.shape)  # number of sick patients"
      ],
      "metadata": {
        "id": "zM3Wd_yAT92F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modéle 1 (K-means)**"
      ],
      "metadata": {
        "id": "xUn0_FH9ZhjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Features = all explanatory columns WITHOUT Classification\n",
        "features = [col for col in df_cancer.columns if col != \"Classification\"]\n",
        "X_cancer = df_cancer[features].values"
      ],
      "metadata": {
        "id": "Y1jH3reiZmAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler_cancer = StandardScaler()\n",
        "X_cancer_scaled = scaler_cancer.fit_transform(X_cancer)\n"
      ],
      "metadata": {
        "id": "O-Qr-Fk2Znjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "inertias = []\n",
        "sil_scores = []\n",
        "K_range = range(2, 5)  # K = 2, 3, 4 for cancer subtypes\n",
        "\n",
        "for k in K_range:\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    km.fit(X_cancer_scaled)\n",
        "    inertias.append(km.inertia_)\n",
        "    labels = km.labels_\n",
        "    sil = silhouette_score(X_cancer_scaled, labels)\n",
        "    sil_scores.append(sil)\n",
        "    print(f\"K={k}: silhouette={sil:.3f}\")\n",
        "\n",
        "# Elobow\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(K_range, inertias, marker='o')\n",
        "plt.xlabel(\"Nombre de clusters K\")\n",
        "plt.ylabel(\"Inertie\")\n",
        "plt.title(\"Méthode du coude – KMeans (patients avec cancer)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Silhouette\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(K_range, sil_scores, marker='o')\n",
        "plt.xlabel(\"Nombre de clusters K\")\n",
        "plt.ylabel(\"Score de silhouette moyen\")\n",
        "plt.title(\"Silhouette – KMeans (patients avec cancer)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RReRKsZ-ZsZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Hierarchical link with Ward's criterion (suitable for standardized continuous data)\n",
        "Z = linkage(X_cancer_scaled, method='ward')\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "dendrogram(Z, truncate_mode=None, color_threshold=None)\n",
        "plt.title(\"Dendrogramme – CAH (patients avec cancer)\")\n",
        "plt.xlabel(\"Patients\")\n",
        "plt.ylabel(\"Distance (Ward)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S2vNpyOMZuyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For k=2"
      ],
      "metadata": {
        "id": "y1Aya4W2Zwrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_k = 2\n",
        "\n",
        "kmeans_cancer = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
        "kmeans_cancer.fit(X_cancer_scaled)\n",
        "\n",
        "cluster_labels_cancer = kmeans_cancer.labels_\n",
        "\n",
        "# Add cluster labels in df_cancer\n",
        "df_cancer[\"cluster_kmeans_cancer\"] = cluster_labels_cancer\n",
        "\n",
        "# If you want to reintegrate into the complete df (NaN for non-patients)\n",
        "df2[\"cluster_kmeans_cancer\"] = np.nan\n",
        "df2.loc[df_cancer.index, \"cluster_kmeans_cancer\"] = cluster_labels_cancer\n"
      ],
      "metadata": {
        "id": "ePtmYC1dZ3-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Average of variables per cluster\n",
        "cluster_profile = df_cancer.groupby(\"cluster_kmeans_cancer\")[features].mean()\n",
        "print(cluster_profile)\n",
        "\n",
        "# Number of patients per cluster\n",
        "print(df_cancer[\"cluster_kmeans_cancer\"].value_counts())\n"
      ],
      "metadata": {
        "id": "o9tuQpm0Z5_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 2D PCA projection for patients with cancer\n",
        "pca_vis = PCA(n_components=2)\n",
        "X_cancer_pca = pca_vis.fit_transform(X_cancer_scaled)\n",
        "\n",
        "# IMPORTANT: add columns to df_cancer\n",
        "df_cancer = df_cancer.copy()\n",
        "df_cancer[\"PC1\"] = X_cancer_pca[:, 0]\n",
        "df_cancer[\"PC2\"] = X_cancer_pca[:, 1]\n"
      ],
      "metadata": {
        "id": "j30Y-Pl5Z7pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.scatterplot(\n",
        "    data=df_cancer,\n",
        "    x=\"PC1\", y=\"PC2\",\n",
        "    hue=\"cluster_kmeans_cancer\",\n",
        "    palette=\"viridis\",\n",
        "    s=60,\n",
        "    edgecolor=\"k\"\n",
        ")\n",
        "plt.xlabel(f\"PC1 ({pca_vis.explained_variance_ratio_[0]*100:.1f} %)\")\n",
        "plt.ylabel(f\"PC2 ({pca_vis.explained_variance_ratio_[1]*100:.1f} %)\")\n",
        "plt.title(\"K-Means (K=2) – Patients avec cancer, projection PCA\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mv-P8eS3Z9lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cluster 0:\n",
        "\n",
        "Younger age, lower BMI, significantly lower glucose, insulin, and HOMA than cluster 1 → less disturbed metabolic profile.\n",
        "\n",
        "Leptin, resistin, and MCP.1 also lower, consistent with more moderate obesity/inflammation.\n",
        "\n",
        "A consistent name: \" Cancers with moderate metabolic risk“ or ”Moderate metabolic subtype.\"\n",
        "\n",
        "Cluster 1:\n",
        "\n",
        "Higher average age (63 years vs. ~53), significantly higher BMI (31), very high glucose (~123), insulin and HOMA multiplied by 3–4 → high insulin resistance/metabolic syndrome. Leptin and MCP.1 much higher, resistin also higher → profile of marked obesity and greater systemic inflammation.\n",
        "\n",
        "A consistent name: “High metabolic risk cancers (obesity and insulin resistance)” or, more briefly, “Severe metabolic subtype.”"
      ],
      "metadata": {
        "id": "plxtd72taBti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For k=3"
      ],
      "metadata": {
        "id": "w5rnO9gzaEib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# We start with df_cancer, features, and X_cancer_scaled already defined.\n",
        "best_k = 3\n",
        "\n",
        "kmeans_cancer_3 = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
        "kmeans_cancer_3.fit(X_cancer_scaled)\n",
        "\n",
        "cluster_labels_cancer_3 = kmeans_cancer_3.labels_\n",
        "df_cancer[\"cluster_kmeans_cancer_3\"] = cluster_labels_cancer_3\n",
        "\n",
        "# Internal quality\n",
        "sil_3 = silhouette_score(X_cancer_scaled, cluster_labels_cancer_3)\n",
        "print(\"Silhouette K=3 (cancers) :\", sil_3)\n"
      ],
      "metadata": {
        "id": "EF-uE5QsaGMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cancer.head(50)"
      ],
      "metadata": {
        "id": "BBm2AAqmaIZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cancer.tail()"
      ],
      "metadata": {
        "id": "VXqgLB6SaK8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of patients per cluster\n",
        "print(df_cancer[\"cluster_kmeans_cancer_3\"].value_counts())\n",
        "\n",
        "# Average of variables per cluster\n",
        "cluster_profile_3 = df_cancer.groupby(\"cluster_kmeans_cancer_3\")[features].mean()\n",
        "print(cluster_profile_3)\n"
      ],
      "metadata": {
        "id": "duztdguiaMjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca_vis_3 = PCA(n_components=2)\n",
        "X_cancer_pca_3 = pca_vis_3.fit_transform(X_cancer_scaled)\n",
        "\n",
        "df_cancer[\"PC1_3\"] = X_cancer_pca_3[:, 0]\n",
        "df_cancer[\"PC2_3\"] = X_cancer_pca_3[:, 1]\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.scatterplot(\n",
        "    data=df_cancer,\n",
        "    x=\"PC1_3\", y=\"PC2_3\",\n",
        "    hue=\"cluster_kmeans_cancer_3\",\n",
        "    palette=\"viridis\",\n",
        "    s=60,\n",
        "    edgecolor=\"k\"\n",
        ")\n",
        "plt.xlabel(f\"PC1 ({pca_vis_3.explained_variance_ratio_[0]*100:.1f} %)\")\n",
        "plt.ylabel(f\"PC2 ({pca_vis_3.explained_variance_ratio_[1]*100:.1f} %)\")\n",
        "plt.title(\"K-Means (K=3) – Patients avec cancer, projection PCA\")\n",
        "plt.legend(title=\"Cluster\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Za_Omu_UaOH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the figure:\n",
        "\n",
        "Cluster 0 (purple) is mainly on the left, with lower PC1 values → cancers with a relatively less disturbed metabolic profile, closer to “normal” in terms of glucose/insulin/HOMA.\n",
        "\n",
        "Cluster 1 (green) occupies the central/right area, with higher PC1 than cluster 0 → cancers with intermediate metabolic abnormalities (higher glucose/HOMA), but not as extreme as cluster 2.\n",
        "\n",
        "Cluster 2 (yellow) includes a few patients on the far right in PC1 → the most extreme cases on the metabolic axis (very high hyperglycemia and/or insulin resistance, probably also high BMI/leptin)."
      ],
      "metadata": {
        "id": "A1gzb6GTaRAZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cluster 0: “Moderate metabolic cancers”\n",
        "\n",
        "Least disturbed metabolic profile among patients.\n",
        "\n",
        "Cluster 1: “Intermediate metabolic risk cancers”\n",
        "\n",
        "Clear but not extreme metabolic abnormalities, central group.\n",
        "\n",
        "Cluster 2: “Severe metabolic cancers (extreme profiles)”\n",
        "\n",
        "A few patients with very marked disorders, located at the extreme end of PC1."
      ],
      "metadata": {
        "id": "bN0ohvXDaSoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modéle 2 (Agglomerative)**"
      ],
      "metadata": {
        "id": "rkpnFAh2afNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# CAH model with k = 3\n",
        "agg_cancer_3 = AgglomerativeClustering(\n",
        "    n_clusters=3,\n",
        "    linkage=\"ward\"       # euclidean + Ward\n",
        ")\n",
        "\n",
        "labels_agg_3 = agg_cancer_3.fit_predict(X_cancer_scaled)\n",
        "\n",
        "# Add labels to df_cancer\n",
        "df_cancer[\"cluster_agg_3\"] = labels_agg_3\n",
        "\n",
        "# (optional) put back into the complete df\n",
        "df2[\"cluster_agg_3\"] = np.nan\n",
        "df2.loc[df_cancer.index, \"cluster_agg_3\"] = labels_agg_3\n",
        "\n",
        "# Silhouette to evaluate quality (optional but useful for comparison with KMeans)\n",
        "sil_agg_3 = silhouette_score(X_cancer_scaled, labels_agg_3)\n",
        "print(\"Silhouette CAH k= :\", sil_agg_3)\n"
      ],
      "metadata": {
        "id": "BVBaWd2vajCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cancer.head(50)"
      ],
      "metadata": {
        "id": "8aZ6knAJalVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_profile_agg_3 = df_cancer.groupby(\"cluster_agg_3\")[features].mean()\n",
        "print(cluster_profile_agg_3)\n",
        "\n",
        "print(df_cancer[\"cluster_agg_3\"].value_counts())\n"
      ],
      "metadata": {
        "id": "Bfq4oUFDangU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# We start with X_cancer_scaled (cancer patients, standardized)\n",
        "pca_agg = PCA(n_components=2)\n",
        "X_cancer_pca_agg = pca_agg.fit_transform(X_cancer_scaled)\n",
        "\n",
        "# Add the components to df_cancer\n",
        "df_cancer[\"PC1_agg\"] = X_cancer_pca_agg[:, 0]\n",
        "df_cancer[\"PC2_agg\"] = X_cancer_pca_agg[:, 1]\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.scatterplot(\n",
        "    data=df_cancer,\n",
        "    x=\"PC1_agg\", y=\"PC2_agg\",\n",
        "    hue=\"cluster_agg_3\",        # labels CAH (0 et 1)\n",
        "    palette=\"Set1\",\n",
        "    s=60,\n",
        "    edgecolor=\"k\"\n",
        ")\n",
        "plt.xlabel(f\"PC1 ({pca_agg.explained_variance_ratio_[0]*100:.1f} %)\")\n",
        "plt.ylabel(f\"PC2 ({pca_agg.explained_variance_ratio_[1]*100:.1f} %)\")\n",
        "plt.title(\"Agglomerative (k=3) – Patients avec cancer, projection PCA\")\n",
        "plt.legend(title=\"Cluster CAH\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "X1yQfX_laqmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modèle 3 (GMM)**\n"
      ],
      "metadata": {
        "id": "2ud_ODNQa0mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Test k = 2, 3, 4\n",
        "K_range = range(2, 5)\n",
        "sil_scores_gmm = []\n",
        "\n",
        "for k in K_range:\n",
        "    gmm = GaussianMixture(\n",
        "        n_components=k,\n",
        "        covariance_type=\"full\",\n",
        "        random_state=42\n",
        "    )\n",
        "    gmm.fit(X_cancer_scaled)\n",
        "\n",
        "    labels = gmm.predict(X_cancer_scaled)\n",
        "    sil = silhouette_score(X_cancer_scaled, labels)\n",
        "    sil_scores_gmm.append(sil)\n",
        "\n",
        "    print(f\"GMM k={k}: silhouette={sil:.3f}\")\n",
        "\n",
        "# Silhouette chart\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(K_range, sil_scores_gmm, marker='o')\n",
        "plt.xlabel(\"Nombre de clusters K\")\n",
        "plt.ylabel(\"Score de silhouette\")\n",
        "plt.title(\"Silhouette – GMM (patients avec cancer)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nQ5ufVI6a2mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Choose the best k\n",
        "best_k_gmm = 3   # (or the best according to silhouette)\n",
        "\n",
        "gmm_final = GaussianMixture(\n",
        "    n_components=best_k_gmm,\n",
        "    covariance_type=\"full\",\n",
        "    random_state=42\n",
        ")\n",
        "gmm_final.fit(X_cancer_scaled)\n",
        "\n",
        "# Labels clusters\n",
        "labels_gmm = gmm_final.predict(X_cancer_scaled)\n",
        "\n",
        "# Add to df_cancer\n",
        "df_cancer[\"cluster_gmm\"] = labels_gmm\n",
        "\n",
        "# Integrate into complete df\n",
        "df2[\"cluster_gmm\"] = np.nan\n",
        "df2.loc[df_cancer.index, \"cluster_gmm\"] = labels_gmm\n",
        "\n",
        "# Clustering quality\n",
        "sil_gmm = silhouette_score(X_cancer_scaled, labels_gmm)\n",
        "print(\"Silhouette GMM :\", sil_gmm)\n",
        "\n",
        "# Number of patients per cluster\n",
        "print(df_cancer[\"cluster_gmm\"].value_counts())\n",
        "\n",
        "# Average cluster profile\n",
        "cluster_profile_gmm = df_cancer.groupby(\"cluster_gmm\")[features].mean()\n",
        "print(cluster_profile_gmm)\n"
      ],
      "metadata": {
        "id": "h1EB8-hVa4nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cancer.head(50)"
      ],
      "metadata": {
        "id": "u5_z_uP4a67C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PCA 2D\n",
        "pca_gmm = PCA(n_components=2)\n",
        "X_cancer_pca_gmm = pca_gmm.fit_transform(X_cancer_scaled)\n",
        "\n",
        "df_cancer[\"PC1_gmm\"] = X_cancer_pca_gmm[:, 0]\n",
        "df_cancer[\"PC2_gmm\"] = X_cancer_pca_gmm[:, 1]\n",
        "\n",
        "# Scatterplot\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.scatterplot(\n",
        "    data=df_cancer,\n",
        "    x=\"PC1_gmm\",\n",
        "    y=\"PC2_gmm\",\n",
        "    hue=\"cluster_gmm\",\n",
        "    palette=\"viridis\",\n",
        "    s=60,\n",
        "    edgecolor=\"k\"\n",
        ")\n",
        "plt.xlabel(f\"PC1 ({pca_gmm.explained_variance_ratio_[0]*100:.1f} %)\")\n",
        "plt.ylabel(f\"PC2 ({pca_gmm.explained_variance_ratio_[1]*100:.1f} %)\")\n",
        "plt.title(\"GMM – Patients avec cancer, projection PCA\")\n",
        "plt.legend(title=\"Cluster GMM\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Vmd4jdAWa8wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = [\"PC1\", \"PC2\", \"PC1_3\", \"PC2_3\", \"PC1_agg\", \"PC2_agg\", \"PC1_gmm\",\"PC2_gmm\"]\n",
        "df_cancer = df_cancer.drop(columns=cols_to_drop, errors=\"ignore\")\n"
      ],
      "metadata": {
        "id": "RGJmeKroa-xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cancer.head()"
      ],
      "metadata": {
        "id": "qlf6jhV2bAtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#assign the cluster to the non-patient\n",
        "df_non_cancer[\"cluster_kmeans_cancer\"] = 3\n",
        "df_non_cancer[\"cluster_kmeans_cancer_3\"] = 3\n",
        "df_non_cancer[\"cluster_agg_3\"] = 3\n",
        "df_non_cancer[\"cluster_gmm\"] = 3"
      ],
      "metadata": {
        "id": "TcBh3DZJbCoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_non_cancer.head()"
      ],
      "metadata": {
        "id": "A_UsnzwrbFqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#merge the dfs\n",
        "df_complet = pd.concat([df_cancer, df_non_cancer], axis=0)\n",
        "df_complet = df_complet.sort_index()\n"
      ],
      "metadata": {
        "id": "e95ZJdkcbHjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_complet[\"cluster_kmeans_cancer\"].value_counts())\n",
        "print(df_complet[\"cluster_kmeans_cancer_3\"].value_counts())\n",
        "print(df_complet[\"cluster_agg_3\"].value_counts())\n",
        "print(df_complet[\"cluster_gmm\"].value_counts())\n"
      ],
      "metadata": {
        "id": "9GZ1sfKgbJWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complet.head()"
      ],
      "metadata": {
        "id": "gsTyJ_w41AOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complet.tail()"
      ],
      "metadata": {
        "id": "8mRbTYGy1IOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complet.dtypes"
      ],
      "metadata": {
        "id": "bd7NFC4m0V0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IV.3. DSO3"
      ],
      "metadata": {
        "id": "UJqY8yeRwpuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*We are going to prepare the Coimbra Dataset for the reccomendation system*"
      ],
      "metadata": {
        "id": "WkJFsDilxVvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete = df_complet.copy()"
      ],
      "metadata": {
        "id": "oKweSBGD1oAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete.drop(columns=[\"Classification\"], inplace=True)\n",
        "df_complete.drop(columns=[\"cluster_kmeans_cancer_3\"], inplace=True)\n",
        "df_complete.drop(columns=[\"cluster_agg_3\"], inplace=True)\n",
        "df_complete.drop(columns=[\"cluster_gmm\"], inplace=True)"
      ],
      "metadata": {
        "id": "qGPgnlyG4gmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete = df_complete.rename(columns={\n",
        "    \"cluster_kmeans_cancer\": \"cluster_final\"\n",
        "})"
      ],
      "metadata": {
        "id": "0PnnO4mC6Knz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete.columns\n"
      ],
      "metadata": {
        "id": "EGmoaDBouXng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete.dtypes"
      ],
      "metadata": {
        "id": "pmz7l3AInDfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete.head()"
      ],
      "metadata": {
        "id": "lhHeSYNa80TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete.tail()"
      ],
      "metadata": {
        "id": "PDmIkqvto7hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = [col for col in df_complete.columns if col != \"cluster_final\"]\n",
        "df_cancer_rec = df_complete[df_complete[\"cluster_final\"].isin([0, 1, 2])].copy()\n",
        "df_non_cancer_rec = df_complete[df_complete[\"cluster_final\"] == 3].copy()"
      ],
      "metadata": {
        "id": "lq-gSoT53d1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_non_cancer_rec.tail()"
      ],
      "metadata": {
        "id": "OLbddBWe3hbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_stats = df_non_cancer_rec[features].describe().T\n",
        "baseline_stats = baseline_stats[['mean', 'std', 'min', 'max']]\n",
        "baseline_stats['5th_percentile'] =  df_non_cancer_rec[features].quantile(0.05)\n",
        "baseline_stats['95th_percentile'] = df_non_cancer_rec[features].quantile(0.95)"
      ],
      "metadata": {
        "id": "75rwMcYF4Kna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== HEALTHY REFERENCE RANGES ===\")\n",
        "print(baseline_stats)"
      ],
      "metadata": {
        "id": "k4X7GtNV5CGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean → typical healthy value\n",
        "\n",
        "\n",
        "Std → natural variability\n",
        "\n",
        "\n",
        "Min / Max → extreme observed healthy values\n",
        "\n",
        "\n",
        "5th percentile → the lower boundary of what is still considered normal\n",
        "\n",
        "\n",
        "95th percentile → the upper boundary of what is still considered normal**\n"
      ],
      "metadata": {
        "id": "GlDMgeB05HGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the dataset contains healthy women around 58, slightly overweight (28) they have a normal metabolic glucose profile (88mg/dL) and normal insulin sensitivity (6.9µU/m)**"
      ],
      "metadata": {
        "id": "ZtZ4-iXl6uYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##How far each patient is from the healthy average"
      ],
      "metadata": {
        "id": "Gg0tKOMM7Y1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_z_scores(df, baseline):\n",
        "    z_scores = pd.DataFrame(index=df.index, columns=features)\n",
        "\n",
        "    for feature in features:\n",
        "        mean = baseline.loc[feature, 'mean']\n",
        "        std = baseline.loc[feature, 'std']\n",
        "        z_scores[feature] = (df[feature] - mean) / std\n",
        "\n",
        "    return z_scores\n",
        "\n",
        "z_scores_all = calculate_z_scores(df_complete, baseline_stats)\n"
      ],
      "metadata": {
        "id": "2bujWafc8Fve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Put all your 9 biomarkers in a list\n",
        "features = [\"Age\",\"BMI\",\"Glucose\",\"Insulin\",\"HOMA\",\"Leptin\",\n",
        "            \"Adiponectin\",\"Resistin\",\"MCP.1\"]\n",
        "\n",
        "\n",
        "df_z_with_cluster = z_scores_all.copy()\n",
        "df_z_with_cluster[\"cluster\"] = df_complete[\"cluster_final\"]\n",
        "\n",
        "\n",
        "# One boxplot per feature\n",
        "for feature in features:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.boxplot(data=df_z_with_cluster, x=\"cluster\", y=feature)\n",
        "    plt.title(f\"{feature} Z‑score Distribution per Cluster\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "QZOPY6Qr93_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is shown in these plots**\n",
        "\n",
        "Each boxplot represents the **distribution of Z-scores** for a given variable  \n",
        "(**Age, BMI, Insulin, Leptin, Adiponectin, Resistin, MCP-1**) across the different clusters.\n",
        "\n",
        "Z-scores indicate how far a patient’s value deviates from the dataset average:\n",
        "- **Z = 0** → average value  \n",
        "- **Z > 0** → higher than average  \n",
        "- **Z < 0** → lower than average  \n",
        "\n",
        "\n",
        "**Variable-specific interpretation logic**\n",
        "\n",
        "The following interpretations apply to all boxplots:\n",
        "\n",
        "- **Age**  \n",
        "  Positive Z-scores indicate **older** patients, while negative Z-scores indicate **younger** patients.\n",
        "\n",
        "- **BMI**  \n",
        "  Higher Z-scores correspond to **higher body mass index** relative to the average.\n",
        "\n",
        "- **Insulin & HOMA**  \n",
        "  Higher Z-scores indicate **higher insulin levels** and **greater insulin resistance**.\n",
        "\n",
        "- **Leptin & Resistin**  \n",
        "  Higher Z-scores suggest **altered adipokine levels**, often associated with metabolic imbalance.\n",
        "\n",
        "- **Adiponectin**  \n",
        "  Lower Z-scores indicate **reduced levels**, commonly linked to metabolic dysfunction.\n",
        "\n",
        "- **MCP-1**  \n",
        "  Higher Z-scores reflect **increased inflammatory activity**.\n"
      ],
      "metadata": {
        "id": "sADM-l40EqW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(z_scores_all, cmap=\"coolwarm\", center=0)\n",
        "plt.title(\"Z-score Heatmap for All Biomarkers\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6HTDN80k-LuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Most patients are near normal(light colors)** : biomarker values close to healthy individuals.\n",
        "* 0  → the patient is close to the healthy average\n",
        "\n",
        "\n",
        "* Blue → the patient is below the healthy average\n",
        "\n",
        "\n",
        "* Red → the patient is above the healthy average\n",
        "\n",
        "\n",
        "* Darker colors → stronger deviation\n",
        "\n",
        "\n",
        "* Rows = individual patients\n",
        "\n",
        "\n",
        "* Columns = biomarkers\n",
        "The biggest deviation is in glucose regulation:\n",
        "\n",
        "\n",
        "* High insulin\n",
        "\n",
        "\n",
        "* High glucose\n",
        "\n",
        "\n",
        "* High HOMA\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TGf_vUEUHI2A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Convert Z-score to interpretable severity label"
      ],
      "metadata": {
        "id": "06uIrn9HJIoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_deviation(z_value):\n",
        "\n",
        "    abs_z = abs(z_value)\n",
        "    if abs_z < 1.0:\n",
        "        return \"Normal\"\n",
        "    elif abs_z < 1.5:\n",
        "        return \"Mild\"\n",
        "    elif abs_z < 2.5:\n",
        "        return \"Moderate\"\n",
        "    else:\n",
        "        return \"Severe\"\n",
        "\n",
        "\n",
        "deviation_labels = z_scores_all.applymap(label_deviation)\n",
        "deviation_labels.columns = [f\"{col}_deviation\" for col in deviation_labels.columns]"
      ],
      "metadata": {
        "id": "uj7kmjIJIq3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "deviation_counts = deviation_labels.apply(pd.Series.value_counts)\n",
        "\n",
        "deviation_counts.T.plot(kind=\"bar\", figsize=(14, 6), colormap=\"viridis\")\n",
        "plt.title(\"Deviation Distribution per Biomarker\")\n",
        "plt.ylabel(\"Number of Patients\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title=\"Deviation Level\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_L5w_mcYJjMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create biological meaning dictioctioannry"
      ],
      "metadata": {
        "id": "42CkAH7fWYTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "biological_meaning = {\n",
        "    \"Age\": {\n",
        "        \"full_name\": \"Age\",\n",
        "        \"meaning\": \"Patient's age in years; cancer risk increases with age\",\n",
        "        \"unit\": \"years\",\n",
        "        \"clinical_significance\": \"Age >50 associated with higher breast cancer risk\",\n",
        "        \"mechanism\": \"Accumulation of genetic mutations over time\",\n",
        "        \"normal_range\": None,\n",
        "        \"interpretation\": {\n",
        "            \"High\": \"Increased cancer risk; prioritize screening\",\n",
        "            \"Low\": \"Lower baseline risk but not protective\"\n",
        "        }\n",
        "    },\n",
        "    \"BMI\": {\n",
        "        \"full_name\": \"Body Mass Index\",\n",
        "        \"meaning\": \"Body fat measure; obesity linked to estrogen production and inflammation\",\n",
        "        \"unit\": \"kg/m²\",\n",
        "        \"clinical_significance\": \"BMI >30 increases breast cancer risk by 30-50%\",\n",
        "        \"mechanism\": \"Adipose tissue produces estrogen and inflammatory cytokines\",\n",
        "        \"normal_range\": (18.5, 24.9),\n",
        "        \"interpretation\": {\n",
        "            \"High\": \"Weight reduction reduces cancer risk and improves metabolic health\",\n",
        "            \"Low\": \"Rule out malnutrition or cachexia\"\n",
        "        }\n",
        "    },\n",
        "    \"Glucose\": {\n",
        "        \"full_name\": \"Fasting Blood Glucose\",\n",
        "        \"meaning\": \"Primary energy source; elevated in insulin resistance and diabetes\",\n",
        "        \"unit\": \"mg/dL\",\n",
        "        \"clinical_significance\": \"Hyperglycemia fuels cancer cell growth (Warburg effect)\",\n",
        "        \"mechanism\": \"Cancer cells preferentially use glucose for rapid proliferation\",\n",
        "        \"normal_range\": (70, 100),\n",
        "        \"interpretation\": {\n",
        "            \"High\": \"Target glycemic control to reduce cancer progression risk\",\n",
        "            \"Low\": \"Risk of hypoglycemia; adjust medications\"\n",
        "        }\n",
        "    },\n",
        "    \"Insulin\": {\n",
        "        \"full_name\": \"Fasting Insulin\",\n",
        "        \"meaning\": \"Hormone that regulates glucose uptake; elevated in insulin resistance\",\n",
        "        \"unit\": \"µU/mL\",\n",
        "        \"clinical_significance\": \"Hyperinsulinemia activates IGF-1 pathway promoting cancer growth\",\n",
        "        \"mechanism\": \"Insulin binds to IGF-1 receptors on cancer cells, stimulating proliferation\",\n",
        "        \"normal_range\": (2.6, 24.9),\n",
        "        \"interpretation\": {\n",
        "            \"High\": \"Insulin-sensitizing drugs may reduce cancer risk and progression\",\n",
        "            \"Low\": \"Check C-peptide; may indicate beta-cell dysfunction\"\n",
        "        }\n",
        "    },\n",
        "    \"HOMA\": {\n",
        "        \"full_name\": \"Homeostatic Model Assessment for Insulin Resistance\",\n",
        "        \"meaning\": \"Calculated index of insulin resistance; HOMA = (Glucose × Insulin) / 405\",\n",
        "        \"unit\": \"ratio\",\n",
        "        \"clinical_significance\": \"HOMA >2.5 indicates insulin resistance, linked to poor cancer outcomes\",\n",
        "        \"mechanism\": \"Insulin resistance creates pro-growth, pro-inflammatory environment\",\n",
        "        \"normal_range\": (0.5, 2.5),\n",
        "        \"interpretation\": {\n",
        "            \"High\": \"Lifestyle modification and metformin can improve insulin sensitivity\",\n",
        "            \"Low\": \"Normal insulin sensitivity; maintain healthy habits\"\n",
        "        }\n",
        "    },\n",
        "    \"Leptin\": {\n",
        "        \"full_name\": \"Leptin\",\n",
        "        \"meaning\": \"Satiety hormone from adipose tissue; signals energy stores to brain\",\n",
        "        \"unit\": \"ng/mL\",\n",
        "        \"clinical_significance\": \"Elevated leptin in obesity promotes cancer via JAK/STAT pathway\",\n",
        "        \"mechanism\": \"Leptin activates pro-survival and anti-apoptotic signals in cancer cells\",\n",
        "        \"normal_range\": (4, 25),\n",
        "        \"interpretation\": {\n",
        "            \"High\": \"Leptin resistance in obesity; target visceral fat reduction\",\n",
        "            \"Low\": \"May indicate low body fat or leptin deficiency\"\n",
        "        }\n",
        "    },\n",
        "    \"Adiponectin\": {\n",
        "        \"full_name\": \"Adiponectin\",\n",
        "        \"meaning\": \"Anti-inflammatory adipokine; inversely related to body fat\",\n",
        "        \"unit\": \"µg/mL\",\n",
        "        \"clinical_significance\": \"Low adiponectin linked to cancer risk; protective molecule\",\n",
        "        \"mechanism\": \"Activates AMPK pathway, inhibits mTOR (cancer suppression)\",\n",
        "        \"normal_range\": (5, 30),\n",
        "        \"interpretation\": {\n",
        "            \"High\": \"Protective; associated with better metabolic health\",\n",
        "            \"Low\": \"Metabolic dysfunction; increase through exercise and weight loss\"\n",
        "        }\n",
        "    },\n",
        "    \"Resistin\": {\n",
        "        \"full_name\": \"Resistin\",\n",
        "        \"meaning\": \"Pro-inflammatory protein from adipose tissue; promotes insulin resistance\",\n",
        "        \"unit\": \"ng/mL\",\n",
        "        \"clinical_significance\": \"Elevated in inflammation and obesity; linked to cancer progression\",\n",
        "        \"mechanism\": \"Induces NF-κB pathway activation, promoting inflammation and angiogenesis\",\n",
        "        \"normal_range\": (4, 12),\n",
        "        \"interpretation\": {\n",
        "            \"High\": \"Anti-inflammatory interventions critical; monitor CRP\",\n",
        "            \"Low\": \"Low inflammatory state; favorable\"\n",
        "        }\n",
        "    },\n",
        "    \"MCP.1\": {\n",
        "        \"full_name\": \"Monocyte Chemoattractant Protein-1\",\n",
        "        \"meaning\": \"Chemokine that recruits immune cells to sites of inflammation\",\n",
        "        \"unit\": \"pg/dL\",\n",
        "        \"clinical_significance\": \"Elevated MCP-1 promotes tumor-associated macrophage infiltration\",\n",
        "        \"mechanism\": \"Creates pro-tumor microenvironment via M2 macrophage polarization\",\n",
        "        \"normal_range\": (300, 600),\n",
        "        \"interpretation\": {\n",
        "            \"High\": \"Chronic inflammation; consider anti-inflammatory diet and omega-3s\",\n",
        "            \"Low\": \"Reduced inflammatory signaling; favorable\"\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "print(\"✓ Biological meaning dictionary created for\", len(biological_meaning), \"features\")\n",
        "\n"
      ],
      "metadata": {
        "id": "FkW0UPdPWzA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add biological Interpretations to baseline stats"
      ],
      "metadata": {
        "id": "HcnRG-y6W1qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new columns to baseline_stats\n",
        "baseline_stats['biological_meaning'] = \"\"\n",
        "baseline_stats['unit'] = \"\"\n",
        "baseline_stats['clinical_significance'] = \"\"\n",
        "\n",
        "\n",
        "for feature in features:\n",
        "    if feature in biological_meaning:\n",
        "        baseline_stats.loc[feature, 'biological_meaning'] = biological_meaning[feature]['meaning']\n",
        "        baseline_stats.loc[feature, 'unit'] = biological_meaning[feature]['unit']\n",
        "        baseline_stats.loc[feature, 'clinical_significance'] = biological_meaning[feature]['clinical_significance']\n",
        "\n",
        "\n",
        "# Display enriched baseline\n",
        "print(\"=\" * 100)\n",
        "print(\"ENRICHED BASELINE STATISTICS (Healthy Population Reference)\")\n",
        "print(\"=\" * 100)\n",
        "print(baseline_stats.head())\n",
        "print(\"\\n✓ Baseline stats enriched with biological meaning\")"
      ],
      "metadata": {
        "id": "wxzCR5XmXMZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Z_score and deviation labels to df_complete"
      ],
      "metadata": {
        "id": "iVIecLkFXVN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in z_scores_all.columns:\n",
        "    df_complete[f\"{col}_zscore\"] = z_scores_all[col]\n",
        "\n",
        "\n",
        "print(\"✓ Z-scores added to df_complete\")\n",
        "print(f\"  New shape: {df_complete.shape}\")\n",
        "print(f\"  Z-score columns: {[col for col in df_complete.columns if '_zscore' in col][:3]}...\")\n",
        "\n",
        "\n",
        "df_complete = pd.concat([df_complete, deviation_labels], axis=1)\n",
        "\n",
        "\n",
        "print(\"✓ Deviation labels added to df_complete\")\n",
        "print(f\"  New shape: {df_complete.shape}\")\n",
        "print(f\"  Deviation columns: {[col for col in df_complete.columns if '_deviation' in col][:3]}...\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xrKsRDJyLx-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_complete.head()"
      ],
      "metadata": {
        "id": "NhotIBxnX74k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate overall seveeruty score"
      ],
      "metadata": {
        "id": "Kbx6JOcwX2iM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now the question is: “Overall… how sick does this patient look?”**\n",
        "\n",
        "\n",
        "**This is intensity-based.**\n",
        "\n",
        "\n",
        "Two patients can be in the same cluster\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  one is mildly abnormal\n",
        "*  the other is very abnormal"
      ],
      "metadata": {
        "id": "KY2-SqoqYse3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create severity mapping\n",
        "severity_map = {\n",
        "    \"Normal\": 0,\n",
        "    \"Mild\": 1,\n",
        "    \"Moderate\": 2,\n",
        "    \"Severe\": 3\n",
        "}\n",
        "\n",
        "\n",
        "# Convert deviation labels to numeric scores\n",
        "severity_scores = deviation_labels.applymap(lambda x: severity_map[x])\n",
        "\n",
        "\n",
        "# Calculate average severity across all biomarkers for each patient\n",
        "df_complete['overall_severity'] = severity_scores.mean(axis=1)\n",
        "\n",
        "\n",
        "print(f\"✓ Overall severity score calculated\")\n",
        "print(f\"  Range: {df_complete['overall_severity'].min():.2f} - {df_complete['overall_severity'].max():.2f}\")\n",
        "print(f\"  Mean: {df_complete['overall_severity'].mean():.2f}\")\n",
        "\n",
        "\n",
        "# Show distribution by cluster\n",
        "print(\"\\nSeverity by Cluster:\")\n",
        "print(df_complete.groupby('cluster_final')['overall_severity'].agg(['mean', 'std', 'min', 'max']))\n",
        "\n",
        "\n",
        "# Preview some patients\n",
        "print(\"\\nExample patients with different severity levels:\")\n",
        "print(df_complete[['cluster_final', 'overall_severity']].head(10))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BrxekhUnY5SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Biological Interpretations for Each Patient"
      ],
      "metadata": {
        "id": "3a_uStJXaT8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We convert numerical biomarker deviations into human-readable biological\n",
        "interpretations by evaluating deviation magnitude, direction (high/low),\n",
        "and predefined medical knowledge for each biomarker.**\n"
      ],
      "metadata": {
        "id": "5h7H7ENnaWvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```text\n",
        "┌───────────────────────────────────────────────┐\n",
        "│            INPUT (Per Patient)                │\n",
        "│                                               │\n",
        "│  Biomarker Z-score (e.g. Glucose_zscore)      │\n",
        "│                                               │\n",
        "│  Example: Z = +2.1                             │\n",
        "└───────────────────────┬───────────────────────┘\n",
        "                        │\n",
        "                        ▼\n",
        "┌───────────────────────────────────────────────┐\n",
        "│   Is |Z-score| < 1 ?                           │\n",
        "│                                               │\n",
        "│   YES → \"Within normal range\"                  │\n",
        "│   NO  → Continue                              │\n",
        "└───────────────────────┬───────────────────────┘\n",
        "                        │\n",
        "                        ▼\n",
        "┌───────────────────────────────────────────────┐\n",
        "│        Determine Direction                    │\n",
        "│                                               │\n",
        "│   Z-score > 0  → HIGH                         │\n",
        "│   Z-score < 0  → LOW                          │\n",
        "└───────────────────────┬───────────────────────┘\n",
        "                        │\n",
        "                        ▼\n",
        "┌───────────────────────────────────────────────┐\n",
        "│   Lookup Biological Meaning                   │\n",
        "│                                               │\n",
        "│   Feature = Glucose / Insulin / HOMA / ...    │\n",
        "│   Direction = HIGH or LOW                     │\n",
        "│                                               │\n",
        "│   Use predefined medical interpretation       │\n",
        "└───────────────────────┬───────────────────────┘\n",
        "                        │\n",
        "                        ▼\n",
        "┌───────────────────────────────────────────────┐\n",
        "│        OUTPUT (Human Explanation)              │\n",
        "│                                               │\n",
        "│   \"High glucose → impaired regulation\"        │\n",
        "│   \"Low adiponectin → metabolic risk\"           │\n",
        "│                                               │\n",
        "│   One sentence per biomarker                  │\n",
        "└───────────────────────────────────────────────┘\n"
      ],
      "metadata": {
        "id": "GDK9hv_3acDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interpret_deviation(feature, z_score):\n",
        "    \"\"\"Get biological interpretation for a specific deviation\"\"\"\n",
        "    if abs(z_score) < 1.0:\n",
        "        return \"Within normal range\"\n",
        "\n",
        "\n",
        "    direction = \"High\" if z_score > 0 else \"Low\"\n",
        "\n",
        "\n",
        "    if feature in biological_meaning:\n",
        "        interpretation = biological_meaning[feature][\"interpretation\"].get(\n",
        "            direction,\n",
        "            \"Abnormal value - consult specialist\"\n",
        "        )\n",
        "        return f\"{direction}: {interpretation}\"\n",
        "\n",
        "\n",
        "    return f\"{direction} value detected\"\n"
      ],
      "metadata": {
        "id": "Cg419Bv6an_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add interpretation columns for each feature"
      ],
      "metadata": {
        "id": "G2vtc4aEawUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Adding interpretation columns...\")\n",
        "for feature in features:\n",
        "    df_complete[f\"{feature}_interpretation\"] = df_complete.apply(\n",
        "        lambda row: interpret_deviation(feature, row[f\"{feature}_zscore\"]),\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "\n",
        "print(f\"✓ Biological interpretations added for {len(features)} features\")\n"
      ],
      "metadata": {
        "id": "3sD985xjatvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"-\"*80)\n",
        "print(\"EXAMPLE: Patient Interpretations\")\n",
        "print(\"-\"*80)\n",
        "sample_patient_idx = df_cancer_rec.index[0]  # First cancer patient\n",
        "print(f\"\\nPatient ID: {sample_patient_idx}\")\n",
        "print(f\"Cluster: {df_complete.loc[sample_patient_idx, 'cluster_final']}\")\n",
        "print(f\"Overall Severity: {df_complete.loc[sample_patient_idx, 'overall_severity']:.2f}\")\n",
        "\n",
        "\n",
        "print(\"\\nBiomarker Interpretations:\")\n",
        "for feature in ['Glucose', 'Insulin', 'HOMA', 'Leptin', 'Adiponectin']:\n",
        "    value = df_complete.loc[sample_patient_idx, feature]\n",
        "    zscore = df_complete.loc[sample_patient_idx, f\"{feature}_zscore\"]\n",
        "    deviation = df_complete.loc[sample_patient_idx, f\"{feature}_deviation\"]\n",
        "    interpretation = df_complete.loc[sample_patient_idx, f\"{feature}_interpretation\"]\n",
        "\n",
        "\n",
        "    print(f\"\\n{feature}:\")\n",
        "    print(f\"  Value: {value:.2f} | Z-score: {zscore:.2f} | Severity: {deviation}\")\n",
        "    print(f\"  → {interpretation}\")"
      ],
      "metadata": {
        "id": "trrsDFqQa17r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Profile clusters with biological meaning"
      ],
      "metadata": {
        "id": "1WU1OdKccvet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean Z-scores for each cluster (cancer patients only)\n",
        "z_scores_cancer = z_scores_all.loc[df_cancer_rec.index]\n",
        "\n",
        "\n",
        "cluster_z_profiles = z_scores_cancer.groupby(\n",
        "    df_complete.loc[df_cancer_rec.index, 'cluster_final']\n",
        ").mean()\n",
        "\n",
        "\n",
        "print(\"Mean Z-Scores by Cluster:\")\n",
        "print(cluster_z_profiles.round(2))\n",
        "\n",
        "\n",
        "# Detailed cluster profiling\n",
        "cluster_profiles = []\n",
        "\n",
        "\n",
        "for cluster_id in sorted(df_cancer_rec['cluster_final'].unique()):\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"CLUSTER {cluster_id} PROFILE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "\n",
        "    # Get patients in this cluster\n",
        "    cluster_patients = df_complete[df_complete['cluster_final'] == cluster_id]\n",
        "    n_patients = len(cluster_patients)\n",
        "\n",
        "\n",
        "    print(f\"Number of patients: {n_patients}\")\n",
        "    print(f\"Average severity: {cluster_patients['overall_severity'].mean():.2f}\")\n",
        "\n",
        "\n",
        "    # Get mean Z-scores for this cluster\n",
        "    cluster_z_mean = cluster_z_profiles.loc[cluster_id]\n",
        "\n",
        "\n",
        "    # Identify top 3 most abnormal features (by absolute Z-score)\n",
        "    top_features = cluster_z_mean.abs().nlargest(3)\n",
        "\n",
        "\n",
        "    print(f\"\\nTop 3 Defining Abnormalities:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "\n",
        "    profile_data = {\n",
        "        \"cluster_id\": int(cluster_id),\n",
        "        \"n_patients\": n_patients,\n",
        "        \"avg_severity\": float(cluster_patients['overall_severity'].mean()),\n",
        "        \"top_abnormalities\": []\n",
        "    }\n",
        "\n",
        "\n",
        "    for rank, (feature, abs_z) in enumerate(top_features.items(), 1):\n",
        "        z_score = cluster_z_mean[feature]\n",
        "        direction = \"Elevated\" if z_score > 0 else \"Reduced\"\n",
        "\n",
        "\n",
        "        print(f\"\\n{rank}. {feature} ({direction})\")\n",
        "        print(f\"   Z-score: {z_score:.2f} standard deviations from healthy mean\")\n",
        "        print(f\"   Meaning: {biological_meaning[feature]['meaning']}\")\n",
        "        print(f\"   Mechanism: {biological_meaning[feature]['mechanism']}\")\n",
        "        print(f\"   Clinical Significance: {biological_meaning[feature]['clinical_significance']}\")\n",
        "\n",
        "\n",
        "        profile_data[\"top_abnormalities\"].append({\n",
        "            \"feature\": feature,\n",
        "            \"z_score\": float(z_score),\n",
        "            \"direction\": direction,\n",
        "            \"meaning\": biological_meaning[feature]['meaning'],\n",
        "            \"mechanism\": biological_meaning[feature]['mechanism']\n",
        "        })\n",
        "\n",
        "\n",
        "    cluster_profiles.append(profile_data)\n",
        "\n",
        "\n",
        "# Store cluster profiles for later use\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"✓ Cluster profiles created with biological context\")\n",
        "print(f\"  {len(cluster_profiles)} cancer clusters characterized\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YRz_o7MqdKfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLUSTER 0: \"Metabolically Favorable Cancer Patients\" (n=39, severity=0.30)\n",
        "What the data shows:\n",
        "Slightly elevated glucose (0.71σ) - mild concern\n",
        "LOWER BMI (-0.70σ) - actually protective!\n",
        "Lower Leptin (-0.55σ) - less body fat\n",
        "Nearly normal Insulin (0.03σ), HOMA (0.10σ)\n",
        "Normal Adiponectin (0.01σ)\n",
        "Clinical Interpretation: This is the \"good metabolic health despite cancer\" group. These patients have:\n",
        "Lower body fat (hence low BMI and leptin)\n",
        "Normal insulin sensitivity\n",
        "Mild glucose elevation (probably stress-related or early metabolic change)\n",
        "Why this is interesting: These cancer patients have better metabolic profiles than expected. This might represent:\n",
        "Early-stage cancer patients\n",
        "Patients who were metabolically healthy before diagnosis\n",
        "Potential for better treatment response\n",
        "\n",
        "CLUSTER 1: \"Classic Insulin Resistance\" (n=22, severity=0.76)\n",
        "What the data shows:\n",
        "HOMA severely elevated (3.01σ) - SEVERE insulin resistance\n",
        "Insulin very high (2.50σ) - compensatory hyperinsulinemia\n",
        "Glucose high (2.20σ) - losing glycemic control\n",
        "Leptin elevated (0.83σ) - moderate obesity\n",
        "Slightly higher BMI (0.52σ)\n",
        "Clinical Interpretation: This is the \"metabolic syndrome + cancer\" group. Classic insulin resistance pattern:\n",
        "High insulin trying to overcome resistance\n",
        "Glucose starting to rise (pre-diabetic range)\n",
        "Moderate obesity driving the metabolic dysfunction\n",
        "This is your TARGET GROUP for aggressive metabolic interventions!\n",
        "\n",
        "CLUSTER 2: \"Severe Metabolic Crisis\" (n=3, severity=1.67)\n",
        "What the data shows:\n",
        "HOMA EXTREMELY elevated (12.86σ) - OFF THE CHARTS!\n",
        "Glucose severely elevated (10.84σ) - likely diabetic range\n",
        "Insulin very high (5.82σ) - body failing to compensate\n",
        "Resistin very high (2.86σ) - severe inflammation\n",
        "MCP-1 very high (3.39σ) - inflammatory storm\n",
        "Clinical Interpretation: This is the \"metabolic emergency\" group. Only 3 patients, but they're in crisis:\n",
        "Likely have Type 2 Diabetes\n",
        "Severe insulin resistance + inflammatory state\n",
        "May have worst cancer prognosis\n",
        "Probably older (Age Z=0.79) with longer metabolic dysfunction\n"
      ],
      "metadata": {
        "id": "YlSBTyswhtr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Knowledge base from actual coimbra cluster profiles"
      ],
      "metadata": {
        "id": "NZmWSactikgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\"BUILDING KNOWLEDGE BASE FROM ACTUAL CLUSTER ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Based on the real cluster profiles you provided:\n",
        "cluster_strategies = {\n",
        "\n",
        "    # ========================================================================\n",
        "    # CLUSTER 0: Metabolically Favorable Cancer Patients\n",
        "    # ========================================================================\n",
        "    0: {\n",
        "        \"name\": \"Metabolically Favorable Profile\",\n",
        "        # WHY: Low severity (0.30), near-normal insulin markers, lower BMI\n",
        "\n",
        "        \"description\": \"\"\"Patients with relatively preserved metabolic health despite cancer diagnosis.\n",
        "        Lower BMI and leptin suggest less adipose tissue dysfunction. Mild glucose elevation may be\n",
        "        stress-related or early metabolic adaptation to cancer.\"\"\",\n",
        "\n",
        "        \"key_characteristics\": {\n",
        "            \"Glucose\": \"Mildly elevated (0.71σ) - slight concern\",\n",
        "            \"BMI\": \"Below average (-0.70σ) - protective factor\",\n",
        "            \"Leptin\": \"Below average (-0.55σ) - less adiposity\",\n",
        "            \"Insulin_Sensitivity\": \"Preserved (HOMA 0.10σ, Insulin 0.03σ)\"\n",
        "        },\n",
        "\n",
        "        \"priority_interventions\": [\n",
        "            # Focus: MAINTAIN good metabolic status, address mild glucose elevation\n",
        "\n",
        "            \"Monitor fasting glucose monthly to detect early insulin resistance\",\n",
        "            # WHY: Glucose slightly elevated; want to catch progression early\n",
        "\n",
        "            \"Maintain healthy weight - avoid both weight loss AND weight gain\",\n",
        "            # WHY: BMI is already lower; excessive loss could indicate cachexia\n",
        "\n",
        "            \"Balanced Mediterranean diet with emphasis on anti-cancer foods\",\n",
        "            # WHY: Preserve metabolic health while supporting cancer treatment\n",
        "\n",
        "            \"Moderate exercise: 150 min/week moderate-intensity aerobic + strength 2x/week\",\n",
        "            # WHY: Maintain insulin sensitivity without metabolic stress\n",
        "\n",
        "            \"Stress management (yoga, meditation) to address potential stress-induced hyperglycemia\",\n",
        "            # WHY: Mild glucose elevation may be stress-related in otherwise healthy metabolism\n",
        "\n",
        "            \"NO aggressive metabolic drugs needed at this stage\"\n",
        "            # WHY: Metabolic parameters are near-normal; avoid polypharmacy\n",
        "        ],\n",
        "\n",
        "        \"monitoring\": [\n",
        "            \"Fasting glucose monthly (watch for progression toward Cluster 1 pattern)\",\n",
        "            \"HbA1c every 3 months (target <5.7%)\",\n",
        "            \"Weight and BMI monthly (avoid cachexia)\",\n",
        "            \"Comprehensive metabolic panel every 6 months\"\n",
        "        ],\n",
        "\n",
        "        \"dietary_specifics\": [\n",
        "            \"Adequate protein 1.0-1.2 g/kg body weight (prevent muscle loss during cancer treatment)\",\n",
        "            \"Complex carbohydrates with low glycemic index\",\n",
        "            \"Colorful vegetables 5-7 servings/day (phytonutrients for cancer)\",\n",
        "            \"Healthy fats from fish, nuts, olive oil\",\n",
        "            \"Maintain caloric intake - avoid unintentional weight loss\"\n",
        "        ],\n",
        "\n",
        "        \"supplement_recommendations\": [\n",
        "            \"Vitamin D3 2000 IU/day if deficient\",\n",
        "            \"Omega-3 (EPA+DHA) 1-2g/day (anti-inflammatory, cardioprotective during chemo)\",\n",
        "            \"Multivitamin if dietary gaps exist\",\n",
        "            \"NO intensive metabolic supplements needed\"\n",
        "        ],\n",
        "\n",
        "        \"prognosis_note\": \"Best metabolic prognosis group. Focus on maintaining health status.\"\n",
        "    },\n",
        "\n",
        "    # ========================================================================\n",
        "    # CLUSTER 1: Classic Insulin Resistance\n",
        "    # ========================================================================\n",
        "    1: {\n",
        "        \"name\": \"Insulin Resistance Dominant\",\n",
        "        # WHY: HOMA 3.01σ, Insulin 2.50σ, Glucose 2.20σ - classic triad\n",
        "\n",
        "        \"description\": \"\"\"Patients with established insulin resistance and compensatory hyperinsulinemia.\n",
        "        This is the metabolic syndrome phenotype: moderate obesity, high insulin, rising glucose.\n",
        "        Strong evidence that insulin-sensitizing interventions can improve cancer outcomes in this group.\"\"\",\n",
        "\n",
        "        \"key_characteristics\": {\n",
        "            \"HOMA\": \"Severely elevated (3.01σ) - established insulin resistance\",\n",
        "            \"Insulin\": \"Very high (2.50σ) - compensatory hyperinsulinemia\",\n",
        "            \"Glucose\": \"High (2.20σ) - pre-diabetic range likely\",\n",
        "            \"BMI\": \"Elevated (0.52σ) - overweight/obese\",\n",
        "            \"Leptin\": \"Elevated (0.83σ) - leptin resistance from adiposity\"\n",
        "        },\n",
        "\n",
        "        \"priority_interventions\": [\n",
        "            # Focus: AGGRESSIVE insulin sensitization\n",
        "\n",
        "            \"Metformin 500mg BID, titrate to 1000mg BID over 2 weeks (REQUIRES ONCOLOGIST APPROVAL)\",\n",
        "            # WHY: First-line insulin sensitizer; Goodwin et al. showed 25% recurrence reduction\n",
        "            # EVIDENCE: Goodwin PJ et al. J Clin Oncol. 2022;40(12):1353-1361\n",
        "\n",
        "            \"Target 7-10% body weight reduction over 6 months\",\n",
        "            # WHY: Weight loss improves insulin sensitivity by ~30-40%\n",
        "            # EVIDENCE: Wing RR et al. Diabetes Care. 2011;34(7):1481-1486\n",
        "\n",
        "            \"Low glycemic index diet (<100g carbs/day initially)\",\n",
        "            # WHY: Reduces glucose spikes that worsen insulin resistance\n",
        "            # EVIDENCE: Esposito K et al. Diabetologia. 2015;58(4):773-780\n",
        "\n",
        "            \"Exercise prescription: 3x/week resistance training + 150min/week brisk walking\",\n",
        "            # WHY: Muscle contractions increase GLUT4 translocation (insulin-independent glucose uptake)\n",
        "            # EVIDENCE: Strasser B et al. Diabetes Care. 2013;36(4):872-877\n",
        "\n",
        "            \"Consider SGLT2 inhibitor (e.g., Empagliflozin 10mg/day) if glucose >120 mg/dL persistently\",\n",
        "            # WHY: Forces glucose excretion through urine, lowers insulin demand\n",
        "            # EVIDENCE: Deng L et al. Cancer Res. 2021;81(13):3480-3493\n",
        "\n",
        "            \"Intermittent fasting 16:8 protocol (if tolerated during cancer treatment)\",\n",
        "            # WHY: Improves insulin sensitivity and may enhance chemotherapy efficacy\n",
        "            # EVIDENCE: de Groot S et al. BMC Cancer. 2015;15:652\n",
        "        ],\n",
        "\n",
        "        \"monitoring\": [\n",
        "            \"HbA1c monthly (target <6.0%, ideally <5.7%)\",\n",
        "            \"Fasting insulin every 2 months (target <10 µU/mL)\",\n",
        "            \"HOMA-IR monthly (target <2.0)\",\n",
        "            \"Fasting glucose weekly initially, then biweekly (target <100 mg/dL)\",\n",
        "            \"Lipid panel quarterly (insulin resistance worsens dyslipidemia)\",\n",
        "            \"Liver function tests if on metformin (every 3 months)\"\n",
        "        ],\n",
        "\n",
        "        \"dietary_specifics\": [\n",
        "            \"Carbohydrates: <30% of calories (or <100g/day)\",\n",
        "            \"Focus on: non-starchy vegetables, lean proteins, healthy fats\",\n",
        "            \"AVOID: white bread, pasta, rice, potatoes, sugary foods, fruit juice\",\n",
        "            \"Meal timing: Concentrate carbs around exercise\",\n",
        "            \"Protein: 1.2-1.5 g/kg body weight (preserve muscle during weight loss)\"\n",
        "        ],\n",
        "\n",
        "        \"supplement_recommendations\": [\n",
        "            \"Berberine 500mg 3x/day (insulin sensitizer, comparable to metformin)\",\n",
        "            # EVIDENCE: Yin J et al. Metabolism. 2008;57(5):712-717\n",
        "\n",
        "            \"Chromium picolinate 200-400 mcg/day (enhances insulin signaling)\",\n",
        "            # EVIDENCE: Kleefstra N et al. Diabetes Care. 2006;29(8):1826-1832\n",
        "\n",
        "            \"Alpha-lipoic acid 600mg/day (improves glucose metabolism)\",\n",
        "            # EVIDENCE: Ziegler D et al. Diabetes Care. 2004;27(10):2365-2371\n",
        "\n",
        "            \"Inositol 2-4g/day (improves insulin sensitivity)\",\n",
        "            # EVIDENCE: Pintaudi B et al. Int J Endocrinol. 2016;2016:9132052\n",
        "\n",
        "            \"Magnesium 400mg/day (cofactor for insulin signaling)\",\n",
        "            # EVIDENCE: Rodríguez-Morán M et al. Diabetes Care. 2003;26(4):1147-1152\n",
        "        ],\n",
        "\n",
        "        \"prognosis_note\": \"Moderate metabolic risk. Aggressive intervention can normalize insulin sensitivity.\"\n",
        "    },\n",
        "\n",
        "    # ========================================================================\n",
        "    # CLUSTER 2: Severe Metabolic Crisis\n",
        "    # ========================================================================\n",
        "    2: {\n",
        "        \"name\": \"Severe Metabolic Dysfunction with Inflammation\",\n",
        "        # WHY: HOMA 12.86σ (!), Glucose 10.84σ, Resistin 2.86σ, MCP-1 3.39σ\n",
        "\n",
        "        \"description\": \"\"\"CRITICAL: Only 3 patients but with extreme metabolic derangement.\n",
        "        Likely undiagnosed or poorly controlled Type 2 Diabetes with severe insulin resistance.\n",
        "        High inflammatory markers (Resistin, MCP-1) suggest chronic systemic inflammation.\n",
        "        These patients need URGENT endocrinology referral and aggressive intervention.\"\"\",\n",
        "\n",
        "        \"key_characteristics\": {\n",
        "            \"HOMA\": \"EXTREME elevation (12.86σ) - severe insulin resistance\",\n",
        "            \"Glucose\": \"EXTREME elevation (10.84σ) - likely diabetic range (>126 mg/dL fasting)\",\n",
        "            \"Insulin\": \"Very high (5.82σ) - pancreatic exhaustion imminent\",\n",
        "            \"Resistin\": \"Very high (2.86σ) - severe inflammation\",\n",
        "            \"MCP-1\": \"Very high (3.39σ) - inflammatory storm\",\n",
        "            \"Age\": \"Older (0.79σ) - chronic metabolic disease\"\n",
        "        },\n",
        "\n",
        "        \"priority_interventions\": [\n",
        "            # Focus: URGENT medical stabilization + aggressive metabolic correction\n",
        "\n",
        "            \"⚠️ IMMEDIATE ENDOCRINOLOGY REFERRAL - likely need diabetes diagnosis and management\",\n",
        "            # WHY: Glucose Z-score of 10.84 suggests fasting glucose likely >150 mg/dL\n",
        "\n",
        "            \"⚠️ Check HbA1c IMMEDIATELY - likely >7.0% (diabetic range)\",\n",
        "            # WHY: Need to confirm diabetes diagnosis and assess chronic glycemic control\n",
        "\n",
        "            \"Metformin 1000mg BID PLUS second-line agent (GLP-1 agonist preferred)\",\n",
        "            # WHY: Single agent insufficient for this level of dysfunction\n",
        "            # EVIDENCE: GLP-1 agonists reduce CV risk and may have anti-cancer effects\n",
        "            # Davies MJ et al. N Engl J Med. 2017;377(13):1228-1239\n",
        "\n",
        "            \"Consider insulin therapy if glucose >200 mg/dL or HbA1c >9%\",\n",
        "            # WHY: May have pancreatic beta-cell failure; need immediate glycemic control\n",
        "\n",
        "            \"AGGRESSIVE anti-inflammatory protocol:\",\n",
        "            \"  - Omega-3 fatty acids 4g/day (high dose)\",\n",
        "            \"  - Curcumin 1500mg/day with piperine\",\n",
        "            \"  - Low-dose aspirin 81mg daily (if no contraindications)\",\n",
        "            # WHY: Resistin and MCP-1 extremely elevated; need to dampen inflammatory cascade\n",
        "\n",
        "            \"STRICT low-carb diet (<50g carbs/day initially) - essentially ketogenic approach\",\n",
        "            # WHY: Need immediate glucose reduction; standard low-GI diet insufficient\n",
        "\n",
        "            \"Daily blood glucose monitoring (4x/day: fasting, post-meals, bedtime)\",\n",
        "            # WHY: Need tight monitoring to prevent hyperglycemic crisis\n",
        "\n",
        "            \"Assess for diabetic complications: retinopathy, nephropathy, neuropathy\",\n",
        "            # WHY: With this level of hyperglycemia, may already have end-organ damage\n",
        "        ],\n",
        "\n",
        "        \"monitoring\": [\n",
        "            \"⚠️ URGENT: HbA1c immediately, then monthly until <7.0%\",\n",
        "            \"Blood glucose 4x/day with log\",\n",
        "            \"Fasting insulin biweekly (assess pancreatic reserve)\",\n",
        "            \"CRP weekly (monitor inflammation)\",\n",
        "            \"Comprehensive metabolic panel biweekly (watch kidney function - metformin contraindicated if eGFR <30)\",\n",
        "            \"Lipid panel monthly\",\n",
        "            \"Urinalysis for proteinuria (diabetic nephropathy screening)\",\n",
        "            \"Ophthalmology referral for diabetic retinopathy screening\"\n",
        "        ],\n",
        "\n",
        "        \"dietary_specifics\": [\n",
        "            \"STRICT carbohydrate restriction: <50g/day (ketogenic approach)\",\n",
        "            \"Focus: leafy greens, cruciferous vegetables, lean proteins, healthy fats\",\n",
        "            \"ELIMINATE: all refined carbs, sugar, fruit (except berries in small amounts)\",\n",
        "            \"Meal timing: 3 meals/day, no snacking (avoid insulin spikes)\",\n",
        "            \"Consider medical nutrition therapy with registered dietitian\",\n",
        "            \"Adequate hydration (2-3L/day) - prevent diabetic complications\"\n",
        "        ],\n",
        "\n",
        "        \"supplement_recommendations\": [\n",
        "            \"ALL supplements from Cluster 1 PLUS:\",\n",
        "            \"High-dose omega-3: EPA+DHA 4g/day (anti-inflammatory)\",\n",
        "            \"Curcumin 1500mg/day with piperine (NF-κB inhibition)\",\n",
        "            \"Vitamin D3 4000-5000 IU/day (immune modulation)\",\n",
        "            \"Coenzyme Q10 200mg/day (mitochondrial support)\",\n",
        "            \"Probiotics high-CFU strain (gut-inflammation axis)\"\n",
        "        ],\n",
        "\n",
        "        \"prognosis_note\": \"⚠️ HIGHEST METABOLIC RISK GROUP. Require urgent medical intervention. Worst cancer outcomes predicted if metabolic dysfunction not corrected.\"\n",
        "    },\n",
        "\n",
        "    # ========================================================================\n",
        "    # CLUSTER 3: Healthy Control Group\n",
        "    # ========================================================================\n",
        "    3: {\n",
        "        \"name\": \"Healthy Reference Group\",\n",
        "        \"description\": \"Patients without breast cancer diagnosis. Metabolic parameters within normal range.\",\n",
        "\n",
        "        \"priority_interventions\": [\n",
        "            \"Continue current healthy lifestyle habits\",\n",
        "            \"Annual breast cancer screening per guidelines (mammography)\",\n",
        "            \"Annual metabolic screening to detect early changes\",\n",
        "            \"Maintain healthy weight (BMI 18.5-24.9)\",\n",
        "            \"Regular exercise per CDC guidelines (150min/week moderate intensity)\"\n",
        "        ],\n",
        "\n",
        "        \"monitoring\": [\n",
        "            \"Annual comprehensive metabolic panel\",\n",
        "            \"Fasting glucose and lipids annually\",\n",
        "            \"BMI and waist circumference at each medical visit\",\n",
        "            \"Mammography per age-appropriate guidelines\"\n",
        "        ],\n",
        "\n",
        "        \"dietary_specifics\": [\n",
        "            \"Balanced Mediterranean-style diet\",\n",
        "            \"5-7 servings fruits and vegetables daily\",\n",
        "            \"Limit processed foods and added sugars\",\n",
        "            \"Moderate alcohol consumption (if any)\"\n",
        "        ],\n",
        "\n",
        "        \"supplement_recommendations\": [\n",
        "            \"Standard multivitamin if dietary gaps exist\",\n",
        "            \"Vitamin D if deficient (<30 ng/mL)\",\n",
        "            \"Calcium if dietary intake insufficient\"\n",
        "        ],\n",
        "\n",
        "        \"prognosis_note\": \"Low metabolic risk. Focus on prevention and maintenance.\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"✓ Knowledge base created from actual cluster analysis\")\n",
        "print(f\"  Cluster 0 (n=39): Metabolically Favorable - MAINTAIN health\")\n",
        "print(f\"  Cluster 1 (n=22): Insulin Resistance - AGGRESSIVE intervention\")\n",
        "print(f\"  Cluster 2 (n=3):  Metabolic Crisis - ⚠️ URGENT referral\")\n",
        "print(f\"  Cluster 3:      Healthy Controls - PREVENTION focus\")\n",
        "\n"
      ],
      "metadata": {
        "id": "lJVofNu3i5Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Building the Recommendation System"
      ],
      "metadata": {
        "id": "GYn5iEklj0Ti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elaborating Methods for NEW patients**"
      ],
      "metadata": {
        "id": "36Zk05w-kDSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Calculate Z-Scores**\n",
        "\n",
        "numeric deviation from healthy norms"
      ],
      "metadata": {
        "id": "m2w0EhC2Y9RW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_z_scores(self, patient_data):\n",
        "    \"\"\"\n",
        "    Compute Z-scores for each biomarker relative to healthy reference values.\n",
        "\n",
        "    INPUT: patient_data (pandas Series)\n",
        "    OUTPUT: pandas Series of Z-scores per feature\n",
        "    \"\"\"\n",
        "    z_scores = pd.Series(index=self.features, dtype=float)\n",
        "\n",
        "    for feature in self.features:\n",
        "        mean = self.baseline_stats.loc[feature, 'mean']\n",
        "        std = self.baseline_stats.loc[feature, 'std']\n",
        "        z_scores[feature] = (patient_data[feature] - mean) / std\n",
        "\n",
        "    return z_scores\n"
      ],
      "metadata": {
        "id": "R3geHFodZAFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Label Deviation Severity**"
      ],
      "metadata": {
        "id": "A8ruAz3uZDV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridMetabolicRecommendationSystem:\n",
        "\n",
        "    def __init__(self, baseline_stats, cluster_strategies, biological_meaning,\n",
        "                 kmeans_model, scaler):\n",
        "\n",
        "        self.baseline_stats = baseline_stats\n",
        "        self.cluster_strategies = cluster_strategies\n",
        "        self.biological_meaning = biological_meaning\n",
        "        self.kmeans_model = kmeans_model\n",
        "        self.scaler = scaler\n",
        "        self.features = baseline_stats.index.tolist()\n",
        "        # ^ Extract feature names (Age, BMI, Glucose, etc.)\n",
        "\n",
        "        print(\"✓ Recommendation system initialized\")\n",
        "        print(f\"  Baseline stats loaded for {len(self.features)} features\")\n",
        "        print(f\"  Knowledge base contains {len(cluster_strategies)} cluster strategies\")\n"
      ],
      "metadata": {
        "id": "Hvx49Xozj5se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Assign a cluster to a new patient (K-means)**"
      ],
      "metadata": {
        "id": "K-27w4ZmdWyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_cluster(patient_data, is_cancer, scaler, kmeans_model, features):\n",
        "    \"\"\"\n",
        "    Assign a metabolic cluster to a new patient.\n",
        "\n",
        "    INPUT:\n",
        "    - patient_data: pandas Series with biomarker values\n",
        "    - is_cancer: Boolean (True if patient has breast cancer)\n",
        "    - scaler: StandardScaler fitted on training data\n",
        "    - kmeans_model: Trained KMeans model (trained only on cancer patients)\n",
        "    - features: list of features used in training\n",
        "\n",
        "    OUTPUT:\n",
        "    - cluster: Integer\n",
        "        0,1,2 -> cancer clusters\n",
        "        3     -> healthy patient\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 1: Check if patient has cancer\n",
        "    if not is_cancer:\n",
        "        return 3  # Healthy patient, skip KMeans\n",
        "\n",
        "    # Step 2: Extract features in same order as training\n",
        "    patient_values = patient_data[features].values.reshape(1, -1)\n",
        "\n",
        "    # Step 3: Scale patient data using training scaler\n",
        "    patient_scaled = scaler.transform(patient_values)\n",
        "\n",
        "    # Step 4: Predict cluster using trained KMeans model\n",
        "    cluster = kmeans_model.predict(patient_scaled)[0]\n",
        "\n",
        "    return int(cluster)\n"
      ],
      "metadata": {
        "id": "gqK2D6PideZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Calculate Overall Severity Score**\n",
        "\n",
        "Get overall severity score for a patient"
      ],
      "metadata": {
        "id": "17pKQGFxdi9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_severity_score(self, deviation_labels):\n",
        "    \"\"\"\n",
        "    Aggregate severity across all biomarkers into a single score.\n",
        "\n",
        "    INPUT:\n",
        "    - deviation_labels: pandas Series of \"Normal\"/\"Mild\"/\"Moderate\"/\"Severe\"\n",
        "\n",
        "    OUTPUT:\n",
        "    - severity_score: float between 0.0 (all normal) and 3.0 (all severe)\n",
        "    \"\"\"\n",
        "    severity_map = {\n",
        "        \"Normal\": 0,\n",
        "        \"Mild\": 1,\n",
        "        \"Moderate\": 2,\n",
        "        \"Severe\": 3\n",
        "    }\n",
        "\n",
        "    # Convert labels to numeric, ignoring unknown labels\n",
        "    numeric_severities = deviation_labels.map(severity_map).dropna()\n",
        "\n",
        "    # Compute average severity\n",
        "    severity_score = numeric_severities.mean()\n",
        "\n",
        "    return float(severity_score)\n"
      ],
      "metadata": {
        "id": "Zub261gXdlUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.Generate Feature-Specific Recommendations**\n",
        "\n",
        "Return list of specific interventions for a biomarker\n",
        "\n",
        "Recommendations are meant to be actionable and focused on significant abnormalities (Moderate/Severe)"
      ],
      "metadata": {
        "id": "UpaU-zcXdoh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_recommendations(self, feature, z_score, deviation):\n",
        "    \"\"\"\n",
        "    Generate biomarker-specific recommendations based on deviation.\n",
        "\n",
        "    INPUT:\n",
        "    - feature:= \"Insulin\"...\n",
        "    - z_score: float, deviation from healthy mean\n",
        "    - deviation: \"Normal\", \"Mild\", \"Moderate\", \"Severe\"\n",
        "\n",
        "    OUTPUT:\n",
        "    - recommendations: list of strings with actionable advice\n",
        "    \"\"\"\n",
        "    recommendations = []\n",
        "\n",
        "    # Only provide recommendations for moderate/severe deviations\n",
        "    if deviation not in [\"Moderate\", \"Severe\"]:\n",
        "        return recommendations\n",
        "\n",
        "    # Determine direction\n",
        "    # Positive Z-score = above healthy mean (High)\n",
        "    # Negative Z-score = below healthy mean (Low)\n",
        "    direction = \"High\" if z_score > 0 else \"Low\"\n",
        "\n",
        "\n",
        "    # Look up recommendations from knowledge base\n",
        "    if feature in self.biological_meaning:\n",
        "        interpretation = self.biological_meaning[feature][\"interpretation\"].get(\n",
        "            direction,\n",
        "            \"Abnormal value detected - consult specialist\"\n",
        "        )\n",
        "        recommendations.append(interpretation)\n",
        "\n",
        "    return recommendations\n"
      ],
      "metadata": {
        "id": "qLAkiz2HdrPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Main Recommendation Generation**"
      ],
      "metadata": {
        "id": "HF7BxsT-dvlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HybridMetabolicRecommendationSystem:\n",
        "\n",
        "    def __init__(self, baseline_stats, cluster_strategies, biological_meaning,\n",
        "                 kmeans_model, scaler):\n",
        "        self.baseline_stats = baseline_stats\n",
        "        self.cluster_strategies = cluster_strategies\n",
        "        self.biological_meaning = biological_meaning\n",
        "        self.kmeans_model = kmeans_model\n",
        "        self.scaler = scaler\n",
        "        self.features = baseline_stats.index.tolist()\n",
        "\n",
        "        print(\"✓ Recommendation system initialized\")\n",
        "        print(f\"  Baseline stats loaded for {len(self.features)} features\")\n",
        "        print(f\"  Knowledge base contains {len(cluster_strategies)} cluster strategies\")\n",
        "\n",
        "    def calculate_z_scores(self, patient_data):\n",
        "        z_scores = pd.Series(index=self.features, dtype=float)\n",
        "\n",
        "        for feature in self.features:\n",
        "            mean = self.baseline_stats.loc[feature, 'mean']\n",
        "            std = self.baseline_stats.loc[feature, 'std']\n",
        "            z_scores[feature] = (patient_data[feature] - mean) / std\n",
        "\n",
        "        return z_scores\n",
        "\n",
        "    def label_deviations(self, z_scores):\n",
        "        labels = pd.Series(index=z_scores.index, dtype=str)\n",
        "\n",
        "        for feature in z_scores.index:\n",
        "            abs_z = abs(z_scores[feature])\n",
        "\n",
        "            if abs_z < 1.0:\n",
        "                labels[feature] = \"Normal\"\n",
        "            elif abs_z < 1.5:\n",
        "                labels[feature] = \"Mild\"\n",
        "            elif abs_z < 2.5:\n",
        "                labels[feature] = \"Moderate\"\n",
        "            else:\n",
        "                labels[feature] = \"Severe\"\n",
        "\n",
        "        return labels\n",
        "\n",
        "    def assign_cluster(self, patient_data, is_cancer=True):\n",
        "        if not is_cancer:\n",
        "            return 3\n",
        "        patient_values = patient_data[self.features].values.reshape(1, -1)\n",
        "        patient_scaled = self.scaler.transform(patient_values)\n",
        "        cluster = self.kmeans_model.predict(patient_scaled)[0]\n",
        "        return int(cluster)\n",
        "\n",
        "    def calculate_severity_score(self, deviation_labels):\n",
        "        severity_map = {\"Normal\": 0, \"Mild\": 1, \"Moderate\": 2, \"Severe\": 3}\n",
        "        numeric_severities = deviation_labels.map(severity_map).dropna()\n",
        "        return float(numeric_severities.mean())\n",
        "\n",
        "    def get_feature_recommendations(self, feature, z_score, deviation):\n",
        "        recommendations = []\n",
        "        if deviation not in [\"Moderate\", \"Severe\"]:\n",
        "            return recommendations\n",
        "        direction = \"High\" if z_score > 0 else \"Low\"\n",
        "        if feature in self.biological_meaning:\n",
        "            interpretation = self.biological_meaning[feature][\"interpretation\"].get(\n",
        "                direction,\n",
        "                \"Abnormal value detected - consult specialist\"\n",
        "            )\n",
        "            recommendations.append(interpretation)\n",
        "        return recommendations\n",
        "\n",
        "    def _interpret_severity(self, severity_score):\n",
        "        if severity_score < 0.5:\n",
        "            return \"Low Risk/Well-Controlled\"\n",
        "        elif severity_score < 1.0:\n",
        "            return \"Moderate Risk/Needs Attention\"\n",
        "        elif severity_score < 2.0:\n",
        "            return \"High Risk/Urgent Intervention\"\n",
        "        else:\n",
        "            return \"Critical Risk/Emergency\"\n",
        "\n",
        "    def generate_recommendations(self, patient_data, is_cancer=True):\n",
        "        z_scores = self.calculate_z_scores(patient_data)\n",
        "        deviations = self.label_deviations(z_scores)\n",
        "        severity_score = self.calculate_severity_score(deviations)\n",
        "        cluster = self.assign_cluster(patient_data, is_cancer)\n",
        "        cluster_info = self.cluster_strategies[cluster]\n",
        "\n",
        "        recommendations = list(cluster_info[\"priority_interventions\"])\n",
        "        explanations = [f\"Patient assigned to '{cluster_info['name']}' based on metabolic profile. Primary strategy: {cluster_info['description']}...\"]\n",
        "\n",
        "        for feature in self.features:\n",
        "            z = z_scores[feature]\n",
        "            deviation = deviations[feature]\n",
        "            if deviation in [\"Moderate\", \"Severe\"]:\n",
        "                feature_recs = self.get_feature_recommendations(feature, z, deviation)\n",
        "                recommendations.extend(feature_recs)\n",
        "                direction = \"elevated\" if z > 0 else \"reduced\"\n",
        "                explanation = (\n",
        "                    f\"{feature}: {patient_data[feature]:.2f} \"\n",
        "                    f\"({deviation}, {z:.2f}σ {direction}) - \"\n",
        "                    f\"{self.biological_meaning[feature]['clinical_significance']}\"\n",
        "                )\n",
        "                explanations.append(explanation)\n",
        "\n",
        "        recommendations = list(set(recommendations))\n",
        "        output = {\n",
        "            \"patient_profile\": {\n",
        "                \"cluster\": int(cluster),\n",
        "                \"cluster_name\": cluster_info[\"name\"],\n",
        "                \"severity_score\": float(severity_score),\n",
        "                \"cancer_status\": \"Diagnosed\" if is_cancer else \"Healthy\",\n",
        "                \"interpretation\": self._interpret_severity(severity_score)\n",
        "            },\n",
        "            \"biomarker_analysis\": {\n",
        "                feature: {\n",
        "                    \"value\": float(patient_data[feature]),\n",
        "                    \"z_score\": float(z_scores[feature]),\n",
        "                    \"deviation\": deviations[feature],\n",
        "                    \"interpretation\": self.biological_meaning.get(feature, {}).get(\"meaning\", \"\"),\n",
        "                    \"clinical_significance\": self.biological_meaning.get(feature, {}).get(\"clinical_significance\", \"\")\n",
        "                } for feature in self.features\n",
        "            },\n",
        "            \"recommendations\": {\n",
        "                \"priority_interventions\": recommendations,\n",
        "                \"monitoring_plan\": cluster_info[\"monitoring\"],\n",
        "                \"dietary_guidance\": cluster_info[\"dietary_specifics\"],\n",
        "                \"supplement_protocol\": cluster_info.get(\"supplement_recommendations\", [])\n",
        "            },\n",
        "            \"explanations\": explanations,\n",
        "            \"clinical_notes\": {\n",
        "                \"prognosis\": cluster_info.get(\"prognosis_note\", \"\"),\n",
        "                \"cluster_description\": cluster_info[\"description\"]\n",
        "            }\n",
        "        }\n",
        "        return output"
      ],
      "metadata": {
        "id": "hFu6IA65dzK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LLM"
      ],
      "metadata": {
        "id": "s2N3HXjR8rrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq"
      ],
      "metadata": {
        "id": "TBNxFc03UDJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GROQ_API_KEY = \"\""
      ],
      "metadata": {
        "id": "Dq3qPK5Y83Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_biomarkers_for_doctor(biomarker_analysis):\n",
        "    \"\"\"Format biomarker data for doctor prompt (technical)\"\"\"\n",
        "    lines = []\n",
        "    for feature, data in biomarker_analysis.items():\n",
        "        if data['deviation'] in ['Moderate', 'Severe']:\n",
        "            lines.append(\n",
        "                f\"- {feature}: {data['value']:.2f} \"\n",
        "                f\"(Z-score: {data['z_score']:.2f}, {data['deviation']}) \"\n",
        "                f\"- {data['clinical_significance']}\"\n",
        "            )\n",
        "    return \"\\n\".join(lines) if lines else \"All biomarkers within normal range\""
      ],
      "metadata": {
        "id": "7xjCqbRpXkx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_biomarkers_for_patient(biomarker_analysis):\n",
        "    \"\"\"Format biomarker data for patient prompt (simple language)\"\"\"\n",
        "    lines = []\n",
        "\n",
        "    # Map medical terms to patient-friendly terms\n",
        "    friendly_names = {\n",
        "        'Glucose': 'Blood Sugar',\n",
        "        'Insulin': 'Insulin Hormone',\n",
        "        'HOMA': 'Insulin Resistance Score',\n",
        "        'BMI': 'Body Weight Index',\n",
        "        'Age': 'Age',\n",
        "        'Leptin': 'Appetite Hormone',\n",
        "        'Adiponectin': 'Protective Hormone',\n",
        "        'Resistin': 'Inflammation Marker',\n",
        "        'MCP.1': 'Inflammation Marker'\n",
        "    }\n",
        "\n",
        "    for feature, data in biomarker_analysis.items():\n",
        "        if data['deviation'] in ['Moderate', 'Severe']:\n",
        "            friendly = friendly_names.get(feature, feature)\n",
        "            direction = \"high\" if data['z_score'] > 0 else \"low\"\n",
        "            lines.append(f\"- Your {friendly} is {direction} ({data['deviation']} concern)\")\n",
        "\n",
        "    return \"\\n\".join(lines) if lines else \"All your test results look good!\""
      ],
      "metadata": {
        "id": "CULAlIC7XoSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Doctor Prompt (Technical & Detailed)\n",
        "DOCTOR_PROMPT_TEMPLATE = \"\"\"You are an expert medical AI assistant providing clinical recommendations to a healthcare professional.\n",
        "\n",
        "**Patient Profile:**\n",
        "- Cluster: {cluster_name}\n",
        "- Cancer Status: {cancer_status}\n",
        "- Severity Score: {severity_score}/3.0 ({interpretation})\n",
        "\n",
        "**Biomarker Analysis:**\n",
        "{biomarker_summary}\n",
        "\n",
        "**Evidence-Based Recommendations:**\n",
        "{raw_recommendations}\n",
        "\n",
        "**Task:** Rewrite these recommendations as a professional clinical report for a doctor. Include:\n",
        "\n",
        "1. **Clinical Summary**: Synthesize the metabolic status in 2-3 sentences\n",
        "2. **Risk Stratification**: Explain why this patient is in this cluster\n",
        "3. **Intervention Priorities**: List top 3-5 interventions with rationale\n",
        "4. **Monitoring Protocol**: Specify tests and frequency\n",
        "5. **Red Flags**: Any urgent concerns requiring immediate attention\n",
        "\n",
        "Use medical terminology. Be precise, evidence-based, and actionable. Format as a structured clinical note.\"\"\"\n",
        "\n",
        "\n",
        "# Patient Prompt (Simple & Empathetic)\n",
        "PATIENT_PROMPT_TEMPLATE = \"\"\"You are a compassionate medical AI assistant explaining health recommendations to a patient in simple, clear terms.\n",
        "\n",
        "**Your Health Profile:**\n",
        "- Health Category: {cluster_name}\n",
        "- Cancer Diagnosis: {cancer_status}\n",
        "- Overall Health Score: {severity_score}/3.0 ({interpretation})\n",
        "\n",
        "**Your Test Results:**\n",
        "{biomarker_summary_simple}\n",
        "\n",
        "**Medical Recommendations:**\n",
        "{raw_recommendations}\n",
        "\n",
        "**Task:** Rewrite these recommendations in patient-friendly language:\n",
        "\n",
        "1. **What This Means**: Explain the test results in simple terms (avoid medical jargon)\n",
        "2. **Why It Matters**: Help them understand how this affects their health and cancer treatment\n",
        "3. **What You Can Do**: Give clear, specific action steps they can start today\n",
        "4. **Encouragement**: End with supportive, motivating words\n",
        "\n",
        "IMPORTANT:\n",
        "- Use simple language (8th grade reading level)\n",
        "- Be empathetic and supportive\n",
        "- Avoid scary or alarming words\n",
        "- Focus on what they CAN control\n",
        "- Make it feel personal and caring\"\"\""
      ],
      "metadata": {
        "id": "w2BbhF1bXwJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "def generate_llm_interpretation(prompt, max_tokens=300):\n",
        "    \"\"\"\n",
        "    Generate interpretation using Groq's free API\n",
        "    MUCH faster and more reliable than HuggingFace!\n",
        "    \"\"\"\n",
        "    try:\n",
        "        client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "        # Truncate if needed (Groq has generous limits)\n",
        "        if len(prompt) > 3000:\n",
        "            prompt = prompt[:3000] + \"\\n\\n[Content truncated due to length. Summarize key points.]\"\n",
        "\n",
        "        print(f\"🔄 Generating with Groq (Llama 3.1)...\")\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"llama-3.1-8b-instant\",  # Fast, free, excellent quality\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"You are an expert medical AI assistant providing clear, accurate clinical recommendations.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": prompt\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "        generated_text = response.choices[0].message.content\n",
        "        print(f\"✅ Generated {len(generated_text)} characters\")\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = str(e)\n",
        "        print(f\"❌ Groq Error: {error_msg}\")\n",
        "\n",
        "        # Provide helpful error messages\n",
        "        if \"api_key\" in error_msg.lower():\n",
        "            return \"[Error: Invalid API key. Get a free key at https://console.groq.com/keys]\"\n",
        "        elif \"rate limit\" in error_msg.lower():\n",
        "            return \"[Error: Rate limit exceeded. Groq free tier: 30 requests/min. Please wait.]\"\n",
        "        else:\n",
        "            return f\"[Error: {error_msg[:200]}]\""
      ],
      "metadata": {
        "id": "mr4NlvG183Yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_llm_interpretations(recsys_instance, recommendations_dict, target_audience=\"doctor\"):\n",
        "    \"\"\"\n",
        "    Generate human-like interpretation - now using Groq!\n",
        "    \"\"\"\n",
        "    profile = recommendations_dict['patient_profile']\n",
        "    biomarkers = recommendations_dict['biomarker_analysis']\n",
        "    raw_recs = recommendations_dict['recommendations']['priority_interventions']\n",
        "\n",
        "    # Build prompt\n",
        "    if target_audience == \"doctor\":\n",
        "        prompt = DOCTOR_PROMPT_TEMPLATE.format(\n",
        "            cluster_name=profile['cluster_name'],\n",
        "            cancer_status=profile['cancer_status'],\n",
        "            severity_score=profile['severity_score'],\n",
        "            interpretation=profile['interpretation'],\n",
        "            biomarker_summary=format_biomarkers_for_doctor(biomarkers),\n",
        "            raw_recommendations=\"\\n\".join([f\"- {r}\" for r in raw_recs[:5]])\n",
        "        )\n",
        "    else:\n",
        "        prompt = PATIENT_PROMPT_TEMPLATE.format(\n",
        "            cluster_name=profile['cluster_name'],\n",
        "            cancer_status=profile['cancer_status'],\n",
        "            severity_score=profile['severity_score'],\n",
        "            interpretation=profile['interpretation'],\n",
        "            biomarker_summary_simple=format_biomarkers_for_patient(biomarkers),\n",
        "            raw_recommendations=\"\\n\".join([f\"- {r}\" for r in raw_recs[:5]])\n",
        "        )\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🎯 Generating {target_audience.upper()} interpretation\")\n",
        "    print(f\"📝 Prompt length: {len(prompt)} characters\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    # Generate\n",
        "    llm_output = generate_llm_interpretation(prompt)\n",
        "\n",
        "    # Fallback if failed\n",
        "    if llm_output.startswith(\"[Error\"):\n",
        "        print(\"⚠️ LLM generation failed, using structured fallback...\")\n",
        "        llm_output = f\"\"\"\n",
        "**Automated Clinical Summary** (LLM temporarily unavailable)\n",
        "\n",
        "**Patient Profile:**\n",
        "- Classification: {profile['cluster_name']}\n",
        "- Severity Score: {profile['severity_score']:.2f}/3.0 ({profile['interpretation']})\n",
        "- Cancer Status: {profile['cancer_status']}\n",
        "\n",
        "**Priority Interventions:**\n",
        "{chr(10).join([f\"{i+1}. {r}\" for i, r in enumerate(raw_recs[:5])])}\n",
        "\n",
        "**Monitoring Plan:**\n",
        "{chr(10).join([f\"• {m}\" for m in recommendations_dict['recommendations']['monitoring_plan'][:3]])}\n",
        "\n",
        "*Please check API configuration and try again.*\n",
        "\"\"\"\n",
        "\n",
        "    recommendations_dict['llm_interpretation'] = {\n",
        "        'audience': target_audience,\n",
        "        'generated_text': llm_output,\n",
        "        'generation_status': 'success' if not llm_output.startswith(\"[Error\") else 'fallback',\n",
        "        'model_used': 'groq-llama-3.1-8b'\n",
        "    }\n",
        "\n",
        "    return recommendations_dict"
      ],
      "metadata": {
        "id": "al5MySoRU0ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# TEST 1: Simple test\n",
        "# ============================================\n",
        "print(\"Testing Groq API...\")\n",
        "test_result = generate_llm_interpretation(\n",
        "    \"Summarize in 2 sentences: Patient has high glucose and needs diet changes.\",\n",
        "    max_tokens=100\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"TEST RESULT:\")\n",
        "print(f\"{'='*60}\")\n",
        "print(test_result)\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# ============================================\n",
        "# TEST 2: Full patient test (only if test 1 works)\n",
        "# ============================================\n",
        "\n",
        "if not test_result.startswith(\"[Error\"):\n",
        "    print(\"✅ API working! Running full patient test...\\n\")\n",
        "\n",
        "    # Your test patient\n",
        "    single_patient = pd.Series({\n",
        "        'Age': 62, 'BMI': 31, 'Glucose': 145, 'Insulin': 28,\n",
        "        'HOMA': 10, 'Leptin': 35, 'Adiponectin': 5,\n",
        "        'Resistin': 15, 'MCP.1': 450\n",
        "    })\n",
        "\n",
        "    # Generate base recommendations\n",
        "    result = recsys.generate_recommendations(single_patient, is_cancer=True)\n",
        "\n",
        "    # Generate doctor interpretation\n",
        "    result_doctor = generate_llm_interpretations(recsys, result, target_audience=\"doctor\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"👨‍⚕️ DOCTOR INTERPRETATION:\")\n",
        "    print(\"=\"*80)\n",
        "    print(result_doctor['llm_interpretation']['generated_text'])\n",
        "\n",
        "    # Generate patient interpretation\n",
        "    result_patient = generate_llm_interpretations(recsys, result, target_audience=\"patient\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"👤 PATIENT INTERPRETATION:\")\n",
        "    print(\"=\"*80)\n",
        "    print(result_patient['llm_interpretation']['generated_text'])\n",
        "else:\n",
        "    print(\"❌ Please set your GROQ_API_KEY first!\")\n",
        "    print(\"Get one free at: https://console.groq.com/keys\")"
      ],
      "metadata": {
        "id": "69I21nONU3R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#V. Evaluation"
      ],
      "metadata": {
        "id": "KYU4lgcMAkyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##V.1. DSO1 : Predict the diagnosis type — M (Malignant) or B (Benign)\n"
      ],
      "metadata": {
        "id": "h6Dk_TSdNp95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Evaluation on the test set Random forest"
      ],
      "metadata": {
        "id": "PCL2-Ivk-lkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- I predict the labels on `X_test` and print:\n",
        "  - the **classification report** (precision, recall, f1-score for Benign and Malignant),\n",
        "  - the **confusion matrix** (number of correct and incorrect predictions).\n",
        "- I also compute the **test accuracy**, which is 0.9766 in my run.\n",
        "- To check that the result is not due to a lucky split, I run a **5-fold cross-validation** on all the data (`X_scaled`, `y_model`).  \n",
        "  The mean cross-validation accuracy is very close to the test accuracy, which suggests that the model generalises well and is not strongly overfitting.\n"
      ],
      "metadata": {
        "id": "Yv8Nd4sa-i6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf.predict(X_test)\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "sAWuGk6KsSL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Evaluation on the test set\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "j2_5fNKTeahm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_mean = cross_val_score(rf, X_scaled, y_model, cv=5).mean()\n",
        "print(f\"Mean Cross-Validation Accuracy (5-fold): {cv_mean:.4f}\")"
      ],
      "metadata": {
        "id": "EojozOBEsUdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve and AUC random forest\n"
      ],
      "metadata": {
        "id": "oAQQgG35-5O9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Probabilités pour la classe 1 (Malignant)\n",
        "y_test_proba = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Courbe ROC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
        "auc_rf = roc_auc_score(y_test, y_test_proba)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f\"Random Forest ROC (AUC = {auc_rf:.3f})\", color=\"darkred\", linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Courbe ROC – Random Forest (Test set)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZiAEc0nv5tkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROC curve of the Random Forest on the test set is very close to the top-left\n",
        "corner. The Area Under the Curve is **AUC = 0.997**, which indicates an excellent\n",
        "ability to separate benign (0) from malignant (1) tumours.  \n",
        "The model keeps a very high true positive rate (sensitivity) while maintaining a\n",
        "very low false positive rate, which is desirable in a medical screening context."
      ],
      "metadata": {
        "id": "lbZr9gzURyFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Hyperparameter search with GridSearchCV mlp"
      ],
      "metadata": {
        "id": "6yuhwRBVWFGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Search space:\n",
        "  - `hidden_layer_sizes`:\n",
        "    - `(32,)`, `(64,)`  → one hidden layer\n",
        "    - `(32, 16)`, `(64, 32)` → two hidden layers\n",
        "  - `alpha` ∈ {1e-4, 1e-3, 1e-2} (L2 regularisation)\n",
        "  - `learning_rate_init` ∈ {1e-3, 5e-4}\n",
        "- Use `GridSearchCV` with:\n",
        "  - estimator: `mlp_base`\n",
        "  - scoring: `\"accuracy\"`\n",
        "  - `cv = 5`\n",
        "- Fit the grid on all data (`X_scaled`, `y_model_2`) and display:\n",
        "  - best hyperparameters\n",
        "  - best mean CV accuracy."
      ],
      "metadata": {
        "id": "7VXhOQ56WIP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"hidden_layer_sizes\": [\n",
        "        (32,),         # une couche\n",
        "        (64,),\n",
        "        (32, 16),      # deux couches\n",
        "        (64, 32)\n",
        "    ],\n",
        "    \"alpha\": [1e-4, 1e-3, 1e-2],          # régularisation L2\n",
        "    \"learning_rate_init\": [1e-3, 5e-4]    # taux d’apprentissage\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    estimator=mlp_base,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=5,\n",
        "    n_jobs=-1\n",
        ")"
      ],
      "metadata": {
        "id": "rqcvBF1-z17b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.fit(X_scaled, y_model_2)"
      ],
      "metadata": {
        "id": "18q8sZxpw8l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== Meilleurs hyperparamètres trouvés ===\")\n",
        "print(grid.best_params_)\n",
        "print(f\"Meilleure accuracy moyenne CV (5-fold): {grid.best_score_:.4f}\")"
      ],
      "metadata": {
        "id": "5PEEwjAkxCfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation on the test set mlp"
      ],
      "metadata": {
        "id": "gbcczozQWRA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Take the best estimator returned by `GridSearchCV` and refit it on the **training set**.\n",
        "- On the test set:\n",
        "  - print the **classification report** (precision, recall, f1-score),\n",
        "  - print the **confusion matrix**,\n",
        "  - compute the **test accuracy**.\n",
        "- Also compute the **training accuracy** to check overfitting.\n",
        "- In my run:\n",
        "  - Test accuracy ≈ 0.977\n",
        "  - Train accuracy ≈ 0.993  \n",
        "  The values are close, which indicates good generalisation and limited overfitting."
      ],
      "metadata": {
        "id": "omS-mxhNWTuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_mlp = grid.best_estimator_\n",
        "best_mlp.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "4ucVXXqw0Hxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_mlp.predict(X_test)\n",
        "print(\"\\n=== Best MLP - Classification Report (Test) ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"=== Best MLP - Confusion Matrix (Test) ===\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "test_acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Best MLP Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Train accuracy pour vérifier l’overfitting\n",
        "y_train_pred = best_mlp.predict(X_train)\n",
        "train_acc = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Best MLP Train Accuracy: {train_acc:.4f}\")"
      ],
      "metadata": {
        "id": "PSt67sdXxEoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve and AUC MLP"
      ],
      "metadata": {
        "id": "e0_815nSWYJa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use `predict_proba` to get the probability of the malignant class on the test set.\n",
        "- Compute and plot the **ROC curve** and the **AUC** for the tuned MLP."
      ],
      "metadata": {
        "id": "nh1nvRYDWa5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_proba = best_mlp.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
        "auc_mlp = roc_auc_score(y_test, y_test_proba)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f\"Best MLP ROC (AUC = {auc_mlp:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"Taux de faux positifs (FPR)\")\n",
        "plt.ylabel(\"Taux de vrais positifs (TPR)\")\n",
        "plt.title(\"Courbe ROC - Best MLP (Test set)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YQl1PzeGxHBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROC curve of the tuned MLP on the test set is very close to the top-left\n",
        "corner, with an AUC of about **0.997**. This shows an excellent ability to\n",
        "separate benign from malignant tumours. Together with a test accuracy around\n",
        "97.7% and a train accuracy slightly higher, the model appears powerful and only\n",
        "mildly overfitted."
      ],
      "metadata": {
        "id": "vrHVnmN4WeEv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Evaluation on the test and train sets gru-svm"
      ],
      "metadata": {
        "id": "AXW7ILu1XXS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The GRU-SVM outputs a real score in ℝ.  \n",
        "  We convert it to labels in {−1, +1} using a **sign threshold at 0**:\n",
        "  - score ≥ 0 → +1 (Malignant)\n",
        "  - score  < 0 → −1 (Benign)\n",
        "- For compatibility with scikit-learn metrics, we also build 0/1 versions:\n",
        "  - `1` = Malignant, `0` = Benign.\n",
        "- On the **test set**, we print:\n",
        "  - classification report,\n",
        "  - confusion matrix,\n",
        "  - test accuracy.\n",
        "- On the **train set**, we compute:\n",
        "  - training accuracy,\n",
        "  - to check for overfitting (train vs test)."
      ],
      "metadata": {
        "id": "N5KliKT3XZjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_scores = gru_svm.predict(X_test_gru).flatten()\n",
        "y_test_pred_svm = np.where(y_test_scores >= 0, 1.0, -1.0)\n",
        "\n",
        "# pour les métriques scikit-learn classiques, on repasse en 0/1\n",
        "y_test_bin = (y_test_gru == 1).astype(int)\n",
        "y_pred_bin = (y_test_pred_svm == 1).astype(int)\n",
        "\n",
        "print(\"\\n=== GRU-SVM - Classification Report (Test) ===\")\n",
        "print(classification_report(y_test_bin, y_pred_bin, target_names=['Benign', 'Malignant']))\n",
        "\n",
        "print(\"=== GRU-SVM - Confusion Matrix (Test) ===\")\n",
        "print(confusion_matrix(y_test_bin, y_pred_bin))\n",
        "\n",
        "test_acc = accuracy_score(y_test_bin, y_pred_bin)\n",
        "print(f\"GRU-SVM Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "rmTzsSOI92w2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Accuracy sur le TRAIN pour détecter l’overfitting ---\n",
        "y_train_scores = gru_svm.predict(X_train_gru).flatten()\n",
        "y_train_pred_svm = np.where(y_train_scores >= 0, 1.0, -1.0)\n",
        "\n",
        "y_train_bin = (y_train_gru == 1).astype(int)\n",
        "y_train_pred_bin = (y_train_pred_svm == 1).astype(int)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train_acc = accuracy_score(y_train_bin, y_train_pred_bin)\n",
        "print(f\"GRU-SVM Train Accuracy: {train_acc:.4f}\")\n",
        "print(f\"GRU-SVM Test  Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "DOAbJcCQ-2lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ROC curve and AUC svm-gru"
      ],
      "metadata": {
        "id": "80dqjMUEXhm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The SVM score is a signed distance to the decision boundary.  \n",
        "  We convert this score to a pseudo-probability using a logistic function:\n",
        "  \\[ p = 1 / (1 + e^{-score}) \\]\n",
        "- With these probabilities, we compute:\n",
        "  - the **ROC curve**,\n",
        "  - the **AUC** for the GRU-SVM on the test set."
      ],
      "metadata": {
        "id": "GhNd-jPCXkFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_proba = 1 / (1 + np.exp(-y_test_scores))\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test_bin, y_test_proba)\n",
        "auc_gru = roc_auc_score(y_test_bin, y_test_proba)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f\"GRU-SVM ROC (AUC = {auc_gru:.3f})\", color=\"navy\", linewidth=2)\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"False Positive Rate (FPR)\")\n",
        "plt.ylabel(\"True Positive Rate (TPR)\")\n",
        "plt.title(\"Courbe ROC – GRU-SVM (Test set)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hrarNCpU95Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROC curve for GRU-SVM is close to the top-left corner with a high AUC\n",
        "(≈ 0.99 in my run). Combined with similar train and test accuracies, this\n",
        "indicates that the GRU-SVM model also achieves very good separation between\n",
        "benign and malignant tumours, without strong overfitting."
      ],
      "metadata": {
        "id": "_4wa1NQzXpdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##V.2. DSO2: Cluster diagnosis patterns\n"
      ],
      "metadata": {
        "id": "qGqniTgUUA7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    silhouette_score, davies_bouldin_score, calinski_harabasz_score,\n",
        "    adjusted_rand_score, normalized_mutual_info_score,\n",
        "    homogeneity_score, completeness_score, v_measure_score\n",
        ")\n",
        "\n",
        "def evaluate_clustering(X2, labels):\n",
        "    results = {}\n",
        "\n",
        "    # Internal metrics\n",
        "    results[\"silhouette\"] = silhouette_score(X2, labels)\n",
        "    results[\"davies_bouldin\"] = davies_bouldin_score(X2, labels)\n",
        "    results[\"calinski_harabasz\"] = calinski_harabasz_score(X2, labels)\n",
        "\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "m04mozjpUGHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_kmeans_3 = evaluate_clustering(\n",
        "    X_cancer_scaled,\n",
        "    df_cancer[\"cluster_kmeans_cancer_3\"]\n",
        ")\n",
        "print(\"Évaluation KMeans k=3 :\")\n",
        "print(results_kmeans_3)\n"
      ],
      "metadata": {
        "id": "46299KW8bOvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_agg = evaluate_clustering(\n",
        "    X_cancer_scaled,\n",
        "    df_cancer[\"cluster_agg_3\"]\n",
        ")\n",
        "print(\"Évaluation Agglomératif :\")\n",
        "print(results_agg)\n"
      ],
      "metadata": {
        "id": "uoBaol1gbQfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_gmm = evaluate_clustering(\n",
        "    X_cancer_scaled,\n",
        "    df_cancer[\"cluster_gmm\"]\n",
        ")\n",
        "print(\"Évaluation GMM :\")\n",
        "print(results_gmm)\n"
      ],
      "metadata": {
        "id": "GBOOlDAQbSXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##V.3. DSO3: Recommandation system\n"
      ],
      "metadata": {
        "id": "bEqYk20Bd3ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recsys = HybridMetabolicRecommendationSystem(\n",
        "    baseline_stats=baseline_stats,\n",
        "    cluster_strategies=cluster_strategies,\n",
        "    biological_meaning=biological_meaning,\n",
        "    kmeans_model=kmeans_cancer_3,\n",
        "    scaler=scaler_cancer,\n",
        ")\n"
      ],
      "metadata": {
        "id": "YKAKzxNGeB05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "single_patient = pd.Series({\n",
        "    'Age': 55,\n",
        "    'BMI': 28,\n",
        "    'Glucose': 120,\n",
        "    'Insulin': 25,\n",
        "    'HOMA': 7,\n",
        "    'Leptin': 15,\n",
        "    'Adiponectin': 8,\n",
        "    'Resistin': 10,\n",
        "    'MCP.1': 3\n",
        "})\n",
        "\n",
        "# Define cancer status for this patient\n",
        "is_cancer = False  # or False if healthy\n",
        "\n",
        "# Generate recommendations\n",
        "result = recsys.generate_recommendations(single_patient, is_cancer=is_cancer)\n",
        "\n",
        "# View main output\n",
        "print(\"Patient Profile:\")\n",
        "print(result['patient_profile'])\n",
        "\n",
        "print(\"\\nPriority Interventions:\")\n",
        "for r in result['recommendations']['priority_interventions']:\n",
        "    print(\"-\", r)\n",
        "\n",
        "print(\"\\nFeature Explanations:\")\n",
        "for e in result['explanations']:\n",
        "    print(\"-\", e)\n"
      ],
      "metadata": {
        "id": "bJ5XbZ28eD3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VI. Deployment"
      ],
      "metadata": {
        "id": "eo7BanEVApLL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PKawi-GAAsVR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}